\documentclass[titlepage]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{latexsym}
\usepackage[left=1in,top=1in,right=1in]{geometry}
\usepackage{setspace}
\usepackage{amsmath, amsthm}
\usepackage{stata}
\usepackage{graphicx}
\usepackage{bm}

\bibliographystyle{sj}
\bibliography{main}

\begin{document}

\author{David Roodman}
\date{Revised October 2010}
\title{Estimating fully observed recursive mixed-process models with {\tt cmp}\thanks{%
Published in \emph{Stata Journal} 11(3), 2011. Thanks to David Drukker, Jonathan Morduch, Zurab Sajaia, and an anonymous reviewer for comments. Correspondence: droodman@cgdev.org.}}
\maketitle

\begin{abstract}
At the heart of many econometric models are a linear function and a normal error. Examples include the classical small-sample linear regression model and the probit, ordered probit, multinomial probit, Tobit, interval regression, and truncated-distribution regression models. Because the normal distribution has a natural multidimensional generalization, such models can be combined into multi-equation systems in which the errors share a multivariate normal distribution. The literature has historically focussed on multi-stage procedures for estimating mixed models, which are more efficient computationally, if less so statistically, than maximum likelihood (ML). But faster computers and simulated likelihood methods such as the Geweke, Hajivassiliou, and Keane (GHK) algorithm for estimating higher-dimensional cumulative normal distributions have made direct ML estimation practical. ML also facilitates a generalization to switching, selection, and other models in which the number and types of equations vary by observation. The Stata module \texttt{cmp} fits Seemingly Unrelated Regressions (SUR) models of this broad family. Its estimator is also consistent for recursive systems in which all endogenous variables appear on the right-hand-sides {\it as observed}. If all the equations are structural, then estimation is full-information maximum likelihood (FIML). If only the final stage or stages are, then it is limited-information maximum likelihood (LIML). {\tt cmp} can mimic a score of built-in and user-written Stata commands. It is also appropriate for a panoply of models previously hard to estimate. Heteroskedasticity, however, can render it inconsistent. This paper explains the theory and implementation of {\tt cmp} and of a related Mata function, {\tt ghk2()}, that implements the GHK algorithm.
\end{abstract}

\doublespacing

\section{Introduction}
Econometrics is most straightforward when dealing with variables whose domains are continuous and unbounded. But economists are often confronted with data that do not come directly from such variables. Sometimes this complication reflects reality: women are either pregnant or not; people do not work for negative numbers of hours. Sometimes it reflects the structure of data collection instruments that, for example, ask yes/no questions and solicit 5-point ratings. A common approach to modeling such {\it limited dependent variables} is to assume that the data-generating process is classically linear and unbounded at its heart, with a normally distributed error term. {\it Link functions} of chosen form translate these {\it latent variables} into the observed ones. Examples include the probit, ordered probit, rank-ordered probit, multinomial probit, and Tobit models, as well as those for interval data and truncated distributions.

Also common are situations in which it is desirable to model or instrument several such variables at once, whether in a Seemingly Unrelated Regressions (SUR) set-up, in which the dependent variables are generated by processes that are independent except for correlated errors, or in the broader simultaneous equations framework, in which endogenous variables influence each other. A poor household's decision about how much microcredit to borrow---a variable censored from the left at 0---might influence the binary variable of a child's enrollment in school, and vice versa. General tools for estimating parameters in such multi-equation systems are rare, perhaps because the likelihoods can be complicated and fitting them computationally demanding.\footnote{The aML package by the late Lee Lillard and Constantijn Panis, now available at applied-ml.com, showed the practicality of a general tool, and indeed is substantially broader than {\tt cmp}. It allows full simultaneity in systems of equations, random effects at various clustering levels, and more model types.} Until recently, official and user-written Stata commands have filled small parts of this space piecemeal. {\tt ivtobit}, for example, implements estimators for Tobit models when some variables on the RHS are endogenous. {\tt heckprob} brings Heckman selection modeling to probit models, making a two-equation system. {\tt cmp} is the first general Stata tool for this class of models, and even it could be extended much further. At this writing, {\tt cmp} implements an estimator for all the model types above except rank-ordered probit; and it allows mixing of these models in multi-equation systems. {\tt cmp} is written as an SUR estimator. Yet it works for a substantially larger class of simultaneous-equation systems, namely, ones having two properties:
\begin{enumerate}
\item {\it Recursivity}, meaning that the equations can be arranged so that the matrix of coefficients of the endogenous variables in each other's equations is triangular. Recursive models have clearly defined stages, with one ore more equations in each stage.

\item What I call {\it full observability}, meaning that endogenous variables appear on the right-sides of equations only as {\it observed}. A dummy endogenous variable, for example, can be included in an equation, but the hypothesized continuous variable latent within it cannot.
\end{enumerate}

Given this mathematical scope, {\tt cmp} is appropriate for two broad types of estimation situations: 1) those in which a truly recursive data-generating process is posited and fully modeled; and 2) those in which there is simultaneity but instruments allow the construction of a recursive set of equations, as in two-stage least squares (2SLS). In the first case, {\tt cmp} is a full-information maximum likelihood (FIML) estimator, all estimated parameters being structural. In the latter, it is a limited-information (LIML) estimator, and only the final stage's (or stages') parameters are structural, the rest being reduced-form.

{\tt cmp} is flexible in another way: models can vary by observation. In other words, they can be conditioned on the data. ``cmp" stands for Conditional Mixed Process. Thus, within the {\tt cmp} universe is the Heckman selection model, in which sample selection, represented by a dummy variable, is modeled in parallel with a dependent variable of interest: selection is modeled for the full data set and the dependent variable for the subset with complete observations. The framework also embraces switching regressions in which the model used for a given variable depends on the data. And it allows suppression of equations that do not apply for particular observations. Pitt and Khandker (1998), in the example that inspired {\tt cmp}, study the effects of male and female microcredit borrowing on household outcomes such as consumption and school enrollment in Bangladesh. Male and female credit are instrumented, but their equations are dropped from the model for households in villages with no program offering credit to their sex. (Notice the mix of processes too: log consumption is continuous and unbounded, enrollment is binary, and credit is censored from the left.)

One measure of the {\tt cmp}'s flexibility is the list of Stata commands it can emulate more or less fully: {\tt probit}, {\tt ivprobit}, {\tt treatreg}, {\tt biprobit}, {\tt tetrachoric}, {\tt oprobit}, {\tt mprobit}, {\tt asmprobit}, {\tt tobit}, {\tt ivtobit}, {\tt cnreg}, {\tt intreg}, {\tt truncreg}, {\tt heckman}, {\tt heckprob}, in principle even {\tt regress}, and {\tt sureg}, as well as the user-written {\tt craggit} (Burke 2009), {\tt triprobit}, {\tt ssm} (Miranda and Rabe-Hasketh 2006), {\tt polychoric} (Kolenikov and Angeles 2004), {\tt mvprobit} (Cappellari and Jenkins 2003), {\tt bitobit}, {\tt mvtobit}, {\tt oheckman} (Chiburis and Lokshin 2007), {\tt switch\_probit} (Lokshin and Sajaia 2011), and {\tt bioprobit} (in its ``non-endogenous" mode; Sajaia 2006). Of course, the purpose of {\tt cmp} is not to replicate capabilities already available, but to make practical a wide array of new ones.

Section \ref{sec:Math} of this paper explains the mathematics of estimating fully observed recursive mixed-process models that are conditioned on the data. Section \ref{sec:Estimation} discusses some practicalities of implementation in Stata. Section \ref{sec:cmp} details how to use {\tt cmp}, with examples and tips.

\section{Fully observed recursive mixed-process models}
\label{sec:Math}
\subsection{The building blocks}
\label{subsec:single models}
We start the exposition by briefly stating the individual models available in {\tt cmp}. All are are built on linear models and the Gaussian distribution, and so can be seen as specific instances of a larger family. All but the multinomial probit model have just one equation. All but classical linear regression and truncated-distribution regression involve censoring. One purpose of this review is to express them all within a unified, formal structure in order to prepare for combining them in mixed models.

\subsubsection{Classical linear regression}
The model is
\begin{align*}
& y^*=\theta +\varepsilon \\
& \theta = {\bf x}'{\bm \beta} \\
& \varepsilon|{\bf x} \sim \text{i.i.d. } \mathcal{N}\left(0,\sigma^2\right)
\end{align*}
where $y$ and $\varepsilon$ are random variables, ${\bf x}={\left (x_1, \hdots,
x_k\right)}'$ is a column vector of $K$ predetermined variables, and ${\bm \beta}$ is a vector of coefficients. For the sake of maximum likelihood (ML) estimation, we assume that the errors are normally distributed, even though they need not be for large-sample Ordinary Least Squares (OLS).

Representing the zero-centered normal distribution by $\phi\left(u;\sigma^2\right)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{u^2}{2\sigma^2}}$, the likelihood for observation $i$ is
\begin{align}
&L_i\left({\bm \beta},\sigma^2;y_i|{\bf x}_i\right)=\phi\left(y_i-\theta_i;\sigma^2\right).
\label{OLS LL}
\end{align}

To express this model and likelihood more universally, we define the probability distribution function for $\varepsilon$ as $f_\varepsilon  \left( u \right) = \phi \left( u;\sigma^2 \right)$; the {\it link function} (trivial in this case) as $g\left(y^*\right)=y$; and an ``error link function" to connect the error process to the outcome:
\begin{align}
h\left( \varepsilon  \right) = g\left( \theta + \varepsilon \right).
\label{h def}
\end{align}
In terms of these functions, the likelihood is (rather pedantically)
\begin{align}
L_i\left({\bm \beta},\sigma^2;y_i|{\bf x}_i\right)=\int\limits_{h^{ - 1} \left( y_i \right)} {f_{\varepsilon} \left( \varepsilon \right)d\varepsilon }
\label{OLS_abstract_LL}
\end{align}
where the domain of integration is the single point
\begin{align}
h^{-1} \left( y_i \right)=\left\{y_i-\theta_i\right\}
\label{OLS h inv}
\end{align}
and the integral of a probability density over such a singleton is interpreted as the density at that point.

\subsubsection{Truncated regression}
In the truncated linear regression model, the dependent variable is confined to some range. An example is studying income determinants among low-income people. The model posits lower and upper truncation points, $\underline \tau_i$ and $\bar \tau_i$, that can vary by observation. For generality, they can take the value $-\infty$ or $\infty$ respectively. Within the sample, the model for $y$ is the same as above. But the likelihood must be normalized by the total probability over the observable range:
\begin{align*}
L_i\left({\bm \beta},\sigma^2,\underline \tau_i,\bar \tau_i;y_i|{\bf x}_i\right)=\displaystyle{\frac{\phi\left(y_i-\theta_i;\sigma^2\right)}{\Phi\left(\bar \tau_i-\theta_i;\sigma^2\right)-\Phi\left(\underline \tau_i-\theta_i;\sigma^2\right)}}
\end{align*}
where $\Phi()$ is the cumulative normal distribution. In more abstract terms, it is
\begin{align}
L_i\left({\bm \beta},\sigma^2,\underline \tau_i,\bar \tau_i;y_i|{\bf x}_i\right)=\frac{\displaystyle{\int\limits_{h^{ - 1} \left( y_i \right)} {f_{\varepsilon} \left( \varepsilon \right)d\varepsilon }}}{\displaystyle{
\int\limits_T {f_\varepsilon \left( \varepsilon \right)d\varepsilon}}}.
\label{Truncated abstract LL}
\end{align}
where $T$ is the region $\left[\underline \tau_i - \theta_i, \bar \tau_i - \theta_i\right]$. If $\underline \tau_i=-\infty$ and $\bar \tau_i=\infty$, the denominator is 1, and this formulation reduces to \eqref{OLS_abstract_LL}.

\subsubsection{Censored (Tobit) regression}
Where truncation excludes observations with the dependent variable outside some range, censoring retains such observations while confining the variable to a range. So the link function is now
\begin{align}
y = g\left(y^*\right)=\left\{\begin{array}{lll}\underline c&\text{if}&y^*\le \underline c \\ y^* & \text{if}&\underline c<y^*<\bar c \\ \bar c & \text{if} & y^*\ge \bar c\end{array}\right.
\label{Tobit model}
\end{align}
where $\underline c$ and $\bar c$ are censoring instead of truncation threshholds. The definition of $h()$ relative to $g()$ in \eqref{h def} does not change. The likelihood is
\begin{align}
L_i\left({\bm \beta},\sigma^2,\underline c,\bar c;y_i|{\bf x}_i\right)=\left\{\begin{array}{lll}
\Phi\left(\underline c-\theta_i;\sigma^2\right)&\text{if}&y_i\le \underline c\\
\phi\left(y_i-\theta_i;\sigma^2\right)&\text{if}&\underline c<y_i< \bar c\\
1-\Phi\left(\bar c-\theta_i;\sigma^2\right)&\text{if}&y_i\ge \bar c
\end{array}\right\}=\int\limits_{h^{ - 1} \left( y_i \right)} {f_{\varepsilon} \left( \varepsilon \right)d\varepsilon }
\label{Tobit LL}
\end{align}
where
\begin{align}
h^{-1} \left( y_i \right)=\left\{\begin{array}{lll}
\left(-\infty, \underline c-\theta_i\right]&\text{if}&y_i\le \underline c\\
\left\{y_i-\theta_i\right\}&\text{if}&\underline c<y_i< \bar c\\
\left[\bar c-\theta_i, \infty\right)&\text{if}&y_i\ge \bar c
\end{array}\right..
\label{Tobit h inv}
\end{align}
If $\underline c=-\infty$ and $\bar c=\infty$, this formula for $h^{-1} \left(\right)$ also reduces to \eqref{OLS_abstract_LL}, so it generalizes \eqref{OLS_abstract_LL} in a different way than \eqref{Truncated abstract LL} does. We will save the grand unification for section \ref{sec:SUR models}.

The Tobit model is so commonplace that its mathematical peculiarity is often overlooked. It mixes cumulative probabilities integrated over one-dimensional ranges with probability densities computed at zero-dimensional points. The overall likelihood is the product of probabilities of both types. It is not obvious that maximizing such a mixed-probability likelihood is consistent. Fifteen years passed between when James Tobin (1958) explored estimators of this type (and he was not the first) and when Takeshi Amemiya (1973) proved their consistency. Later in this paper, we take advantage of this fact in writing down integrals whose domains of integration are all embedded in an error space of fixed dimension, yet whose own dimensions vary by observation along with the number of equations whose realizations are censored. For observations in which none of the equations is censored, the domain of integration will be zero-dimensional, just as for uncensored observations in the one-equation Tobit model. Defining the integrals above to signify probability densities as well as cumulative probabilities paves the way for expressing likelihoods economically.\footnote{A more rigorous statement of the observation-level likelihoods discussed in this section is that they are probability functions (p.f.'s) of $y_i \left\vert \bf x_i \right.$ induced by the maps $h\left(\right)$ into error space. These p.f.'s are in general {\it mixed distributions}, containing both mass points and ranges of continuous distribution. See the discussion of the Stieltjes integral in Ruud (2000, pp. 875--76.).}

A practical complication that is sometimes missed is the way heteroskedasticity can compromise the consistency of ML estimatation of Tobit and other censored models. We defer this issue to section \ref{subsec:het}.

\subsubsection{Probit}
The model is changed from the previous section in that
\begin{align}
y = g\left(y^*\right)=\left\{\begin{array}{lll}0&\text{if}&y^*\le 0\\1&\text{if}&y^*>0\end{array}\right.
\label{Probit model}
\end{align}
This model involves two normalizations. It normalizes {\it location} by setting $0$ as the cut point, which costs nothing in generality if ${\bf x}$ contains a constant. And because it is no longer possible to determine the {\it scale} of $y^*$, the model normalizes to $\sigma^2=1$. But for consistency with the notation of other models, we still include $\sigma^2$ in the equations. The probit link function gives rise to the likelihood
\begin{align*}
L_i\left({\bm \beta},\sigma^2;y_i|{\bf x}_i\right)=\left\{\begin{array}{lll}\Phi\left(-\theta_i;\sigma^2\right)&\text{if}&y_i=0\\
1-\Phi\left(-\theta_i;\sigma^2\right)&\text{if}&y_i=1\end{array}\right\}=\int\limits_{h^{ - 1} \left( y_i \right)} {f_\varepsilon \left( \varepsilon \right)d\varepsilon }
\end{align*}
where $h^{-1} \left( 0\right) = \left(-\infty, -\theta_i\right]$ and $h^{-1} \left( 1\right) = \left(-\theta_i, \infty\right)$.

\subsubsection{Ordered probit}
The ordered probit model is for variables with ordered, discrete values. It generalizes the probit model by slicing the continuum into a finite set of ranges, each corresponding to one possible outcome. Unlike in the Tobit and probit models, the cut points are unknown parameters for estimation. If we wanted to maximize consistency with the definition of the probit model above, we would fix one of the cut points at 0. But we will follow the convention set by Stata's built-in {\tt oprobit} command, which is to make all the cut points free parameters and remove the constant term from ${\bf x}$.

Assume $y$ can achieve $J$ outcomes, $O_1,\hdots,O_J$. Use the ascending sequence of cut points $c_1,\hdots,c_{J-1}$ to define the regions into which $y^*$ might fall, and define $c_0=-\infty$ and $c_J=\infty$. Then the link function is:
\begin{align*}
& y =  g\left(y^*\right) = \left\{\begin{array}{lll}
O_1&\text{if}&c_0<y^*\le c_1\\
\vdots\\
O_j&\text{if}&c_{j-1}<y^*\le c_j\\
\vdots\\
O_J&\text{if}&c_{J-1}<y^*<c_J
\end{array}\right..
\end{align*}
Again, we normalize to $\sigma^2=1$. For the case of $y_i=O_j$, the likelihood is
\begin{align*}
L_i\left({\bm \beta},\sigma^2,c_1,\hdots,c_{J-1};y_i|{\bf x}_i\right)= \Phi\left(c_j-\theta_i;\sigma^2\right)-\Phi\left(c_{j-1}-\theta_i;\sigma^2\right)= \int\limits_{h^{ - 1}\left( y_i \right)} {f_\varepsilon \left(\varepsilon \right)d\varepsilon }
\end{align*}
where the region of integration is
\begin{align}
h^{-1} \left( y_i \right) = \left(c_{j-1}-\theta_i, c_j - \theta_i\right].
\label{oprobit h inv}
\end{align}

\subsubsection{Interval regression}
The interval regression model is identical to that for ordered probit, except that cut points are known. An agricultural census, for example, might report farm landholdings by bracket: less than 1 hectare, 1--10 hectares, 10--100 hectares, etc. So the likelihood when $y_i=O_j$ differs only in having a shorter parameter list on the left:
\begin{align*}
L_i\left({\bm \beta},\sigma^2; y_i|{\bf x}_i\right)= \Phi\left(c_j-\theta_i;\sigma^2\right)-\Phi\left(c_{j-1}-\theta_i;\sigma^2\right)= \int\limits_{h^{ - 1}\left( y_i \right)} {f_\varepsilon \left(\varepsilon \right)d\varepsilon } .
\end{align*}

\subsubsection{Multinomial probit}
\label{subsec:Multinomial probit}
The multinomial probit model applies to situations in which an agent chooses from alternatives that are not inherently ordered, such as the brand of car to buy or whether to fly or drive to a destination. All that is observed is the chosen alternative. Observations are often called {\it cases}, and the agent in each case chooses from a discrete set of {\it alternatives}. The model is more complicated than any of the foregoing ones because it involves multiple equations. (See Long and Freese (2006, ch. 7) and Train (2003, ch. 5) for more.) Readers may prefer to skip this discussion for now, as well as the formal statement of the SUR model that follows, which is complicated by the need to embrace multinomial probits, and instead study the examples after that.

The model posits one ``utility" equation for each alternative, indexed by $j=1,\hdots,J$:
\begin{align*}
& y_j^*=\theta_j+\varepsilon_j \\
& \theta_j ={\bf x}_j'{\bm \beta}_j.
\end{align*}
The ${\bf x}_j$ can be distinct variable sets, but overlap. A regressor that appears in every equation, such as buyer's income in a car choice model, is {\it case-specific}. The opposite, an {\it alternative-specific} variable, such a car's fuel economy, can be thought of as a single variable that varies across alternatives. But the structure used here treats it as a set of variables, one for each equation: Ford fuel economy, Volkswagen fuel economy, etc. The $\varepsilon_j$ can be correlated, according to ${\bm \varepsilon}=\left(\varepsilon_1,\hdots,\varepsilon_J\right)'\sim\mathcal{N}\left({\bm 0},{\bm \Sigma}\right)$. The alternative with the highest utility is chosen.

Let ${\bm \theta} = \left(\theta_1, \hdots, \theta_J \right)'$ and ${\bf y}^*=\left(y_1^*, \hdots, y_J^*\right)'$. A convenient way to express the outcome is to model a vector of dummy variables ${\bf y}=\left(y_1, \hdots, y_J\right)'$, only one of which can be 1 for any particular case. The vector-valued link function is then
\begin{align*}
{\bf g}\left( {\bf y}^*  \right) &= \left[ {\bf 1}\left\{ k = {\mathop {\arg \max y_j^* }\limits_j  } \right\}; k=1,\hdots, J\right]'
\end{align*}
where ${\bm 1}\left\{\right\}$ is a dummy variable indicating the truth of the bracketed equality.

Because of the nature of choice we can only study determinants of relative, not absolute, desirability. In other words, the equations above are underidentified. For example, if buyer's income is a determinant for every car model, then variation in that variable will only reveal its influence on the {\it relative} attractiveness of various models, not its {\it absolute} impact on each one. To make the model identified, we choose a ``base alternative" and exclude from its equation regressors that appear in the utility equations of all other alternatives. In particular, the constant term is normally excluded for the base alternative.

To derive the likelihood for some case $i$, suppose the agent chooses alternative $k$. The probability that this will happen is the probability that $y^*_{ik}$ is greater than all the other $y_{ij}^*$. To state that precisely, define ${\bf M}_k$ as the $\left(J-1\right)\times J$ matrix made by inserting a column of $-1$'s as the new $k^{th}$ column in the $\left(J-1\right)$ identity matrix. E.g., if there are 4 alternatives and $k=3$,
\begin{align}
{\bf M}_k  = \left[
\begin{array}{*{20}c}
   1 & 0 & { - 1} & 0  \\
   0 & 1 & { - 1} & 0  \\
   0 & 0 & { - 1} & 1  \\
\end{array}
 \right].
\label{M_k}
\end{align}
Left-multiplying a $J$-vector by this matrix subtracts the $k^{th}$ entry from the others and then deletes it. So let ${\bf {\tilde y}}^*={\bf M}_k{\bf y}^*$, ${\bm {\tilde \theta}}={\bf M}_k{\bm \theta}$, and ${\bm {\tilde \varepsilon}}={\bf M}_k{\bm \varepsilon}$. The choice of alternative $k$ implies that the utilities of all other alternatives are negative relative to $k$'s: ${\bf {\tilde y}}^*={\bm {\tilde \theta}}+{\bm {\tilde \varepsilon}}<{\bm 0}$. That is, ${\bm {\tilde \varepsilon}}<-{\bm {\tilde \theta}}$. Finally, define
\begin{align}
{\bm {\tilde \Sigma}}_i \equiv \operatorname{Var}\left[{\bm {\tilde \varepsilon}}\right]=\operatorname{Var}\left[{\bf M}_k{\bm \varepsilon}\right]={\bf M}_k\operatorname{Var}\left[{\bm \varepsilon}\right]{\bf M}'_k={\bf M}_k{\bm \Sigma}{\bf M}'_k.
\label{Sigma_Omega_map}
\end{align}
${\bm {\tilde \Sigma}}$ is indexed by $i$ because it depends on which alternative is chosen in case $i$. The likelihood is then
\begin{align}
L_i\left({\bm \beta}_1,\hdots,{\bm \beta}_J,{\bm \Sigma};{\bf y}_i|{\bf x}_i\right)=\operatorname{Pr}\left({\bm {\tilde \varepsilon}}_i<-{\bm {\tilde \theta}}_i\right)=\Phi\left({\bm {-{\tilde \theta}}};{\bm {\tilde \Sigma}}_i\right)
\label{mprobit_likelihood}
\end{align}
where $\Phi()$ is the multidimensional cumulative normal distribution.

To write this in the more abstract terms of link and distributions functions, let ${\bf {\tilde g}}_i\left(\right)$ be the implied link function from transformed latent variables ${\bf {\tilde y}}^*$ to observed outcomes. Its domain is the set of possible utilities of alternatives other than $k$ relative to alternative $k$; it maps these to vectors of dummies that are 1 only for the chosen, highest-utility alternative. Then define
\begin{align*}
{\tilde f}_{{\bm {\tilde \varepsilon}}_i} \left( {\bf u} \right) &= \phi \left( {{\bf u};{\bm {\tilde \Sigma} }} \right) \\
{\bf {\tilde h}}_i\left({\bm {\tilde \varepsilon}}_i\right) &= {\bf {\tilde g}}_i\left( {\bm {\tilde \theta}}_i + {\bm {\tilde \varepsilon}}_i \right).
\end{align*}
The likelihood can now be expressed in a general form with a multidimensional integral:
\begin{align*}
L_i\left({\bm \beta}_1,\hdots,{\bm \beta}_J,{\bm \Sigma};{\bf y}_i|{\bf x}_i\right)=\int\limits_{{\bf {\tilde h}}^{ - 1}_i\left( {\bf y}_i \right)} {f_{{\bm {\tilde \varepsilon}}_i} \left( {\bm {\tilde \varepsilon}} \right){\bm {d {\tilde \varepsilon}}}}
\end{align*}
where, recall, ${\bf y}_i$ is a vector that is all 0's except for a 1 in the position of the chosen alternative and
\begin{align}
{\bf {\tilde h}}^{ - 1}_i\left( {\bf y}_i \right)=\left\{{\bm {\tilde \varepsilon}} \left| {\bm {\tilde \varepsilon}} < -{\bm {\tilde \theta}} \right. \right\}.
\label{mprobit h inv}
\end{align}
This formula for the likelihood generalizes the earlier ones in pre-transforming the error space (by ${\bf M}_k$) before integrating.

As written, this model still has excess degrees of freedom. While this consideration is important in applying the multinomial probit model, it does not change the mathematical form of the likelihood in \eqref{mprobit_likelihood}, which is our primary interest here. So this discussion of the identification issues is brief.

One issue is that, just as in the probit model, scale needs to be normalized. The analog of setting $\sigma^2=1$ in the probit model is to place a constraint on ${\bm \Sigma}$ or ${\bm {\tilde \Sigma}}_i$. But here we run into a more complicated problem. One consequence of the relative nature of utility is that the likelihood in \eqref{mprobit_likelihood} depends on the $\left(J-1\right)\times\left(J-1\right)$ matrix ${\bm {\tilde \Sigma}}_i$, not the $J\times J$ matrix ${\bm \Sigma}$. Thus not all of the elements of ${\bm \Sigma}$ can be identified. To fit the model, one can impose structure on ${\bm \Sigma}$: $J$ constraints to account for the symmetric ${\bm \Sigma}$ having $J$ more independent elements, plus one more constraint to normalize scale.

Alternatively, one can parameterize using a covariance matrix for relative-differenced errors---relative, that is, to an alternative that is fixed across cases. We take this to be the base alternative, which we assume is alternative 1, and label this covariance matrix ${\bm {\hat \Sigma}}$ to distinguish it from ${\bm {\tilde \Sigma}}_i$, the covariance of the errors relative to the {\it chosen} alternative, which varies by case. Given trial values for ${\bm {\hat \Sigma}}$, the implied values for ${\bm {\tilde \Sigma}}_i$ are readily computed. To see this, return again to the example of $J=4$ and $k=3$. The vector of errors relative to the base alternative is related to the vector relative to the chosen alternative by the transformation
\begin{align*}
{\bf {\tilde \varepsilon }}_i  = \left[ {\begin{array}{*{20}c}
   {\varepsilon_{i1}  - \varepsilon_{i3} }  \\
   {\varepsilon_{i2}  - \varepsilon_{i3} }  \\
   {\varepsilon_{i4}  - \varepsilon_{i3} }  \\
\end{array}} \right] = \left[ {\begin{array}{*{20}c}
   0 & { - 1} & 0  \\
   1 & { - 1} & 0  \\
   0 & { - 1} & 1  \\
\end{array}} \right]\left[ {\begin{array}{*{20}c}
   {\varepsilon_{i2}  - \varepsilon_{i1} }  \\
   {\varepsilon_{i3}  - \varepsilon_{i1} }  \\
   {\varepsilon_{i4}  - \varepsilon_{i1} }  \\
\end{array}} \right] \equiv {\bf N}_3 {\bf \hat \varepsilon }.
\end{align*}
So
\begin{align*}
{\bf {\tilde \Sigma}}_i  = {\mathop{\rm Var}} \left[ {{\bf \varepsilon }_i } \right] = {\mathop{\rm Var}\nolimits} \left[ {{\bf N}_3 {\bf \hat \varepsilon }} \right] = {\bf N}_3 {\mathop{\rm Var}\nolimits} \left[ {{\bf \hat \varepsilon }} \right]{\bf N}_3 '= {\bf N}_3 {\bf \hat \Sigma N}_3 '.
\end{align*}
In general, $N_k$ is $M_k$ without its first column. With this parameterization, just one constraint, such as ${\bf \hat \Sigma}_{11}=1$, is needed, in order to normalize scale.

Unfortunately, both $\bf \Sigma$ and ${\bf \hat \Sigma}$ have disadvantages as bases for parameterization. Maximizing likelihood with respect to ${\bf \hat \Sigma}$ is mathematically sound, but yields estimates of quantities such as ${\mathop{\rm Cov}\nolimits} \left[ \varepsilon_3  - \varepsilon_1 ,\varepsilon_2-\varepsilon_1 \right]$ (an element of ${\bf \hat \Sigma}$) that are hard to interpret. Fitting with respect to ${\bm \Sigma}$ is more intuitive. But it turns out to be surprisingly difficult to impose the needed $J+1$ constraints while guaranteeing that the mapping ${\bm \Sigma} \mapsto {\bm {\hat \Sigma} }={\bf N}_1 {\bm \Sigma}{\bf N}_1'$ is {\it onto}. That is, even when the constraints are minimally arbitrary and meant to remove excess degrees of freedom---not to restrict the model---there may be positive-definite $(J-1)\times(J-1)$ matrices that are valid candidates for ${\bm {\hat \Sigma}}$ yet which are not compatible with the constraints on ${\bm \Sigma}$ (Bunch 1991). This can prevent the model fit from reaching the true optimum. Freese and Long (2006, pp. 327--29) provide an example.

A final, separate complication is that ${\bm {\hat \Sigma}}$ is not identified unless there are alternative-specific regressors, such as fuel economy (Keane 1992). This is why the Stata command {\tt mprobit}, which allows only case-specific variables, makes the assumption of Independence of Irrelevant Alternatives (IIA), i.e., that ${\bm \Sigma}$ is an identity matrix. By \eqref{Sigma_Omega_map}, under the IIA,
\begin{align}
{\bm {\hat \Sigma} }_i = {\bf M}_1 {\bf M}_1' = \left[ {\begin{array}{*{20}c}
   2 & 1 &  \cdots  & 1  \\
   1 & 2 &  \ddots  & 1  \\
    \vdots  &  \ddots  &  \ddots  &  \vdots   \\
   1 & 1 &  \cdots  & 2  \\
\end{array}} \right].
\label{differenced IIA}
\end{align}
The newer {\tt asmprobit} allows alternative-specific variables and frees up the structure of ${\bm \Sigma}$.

\subsection{Multi-equation mixed models}
\subsubsection{The SUR model}
\label{sec:SUR models}
Because all of these models are built on the classical linear regression model with normally distributed errors, they combine naturally into systems of ``seemingly unrelated" equations. Equations in an SUR system seem unrelated in the sense that no endogenous (LHS) variables appear on the right side of other equations. But their errors can be correlated, sharing a multidimensional distribution. Parameters in SUR systems can be consistently estimated equation-by-equation, but simultaneous estimation that takes into account the full covariance structure is in general more efficient.

The SUR model is
\begin{align*}
& \mathop{{{\bf y}^*}'}\limits_{1 \times J}  = \mathop{{\bm \theta}'}\limits_{1 \times J} + \mathop{{\bm \varepsilon}'}\limits_{1 \times J} \\
& \mathop{{\bm \theta}'}\limits_{1 \times J}  = \mathop{{\bf x}'}\limits_{1 \times K} \mathop{\bf B}\limits_{K \times J} \\
& {\bf y} = {\bf g} \left({\bf y}^* \right) = \left( g_1 \left({\bf y}^* \right), \hdots, g_J\left({\bf y}^*\right)\right)'. \\
& {\bm \varepsilon}|{\bf x} \sim \text{i.i.d. } \mathcal{N}\left({\bm 0}, {\bm \Sigma}\right)
\end{align*}
where ${\bf B}$ is a matrix of coefficients, ${\bf y}$ and ${\bm \varepsilon}$
are random vectors, and ${\bf x}={\left (x_1, \hdots,
x_k\right)}'$ is a vector of predetermined random variables. In general, constraints can be imposed on ${\bf B}$ and ${\bm \Sigma}$---for example, not all elements of ${\bf x}$ need enter every equation---but we will ignore this complexity for the sake of exposition.

Variables of most types require just one equation within the system. But a multinomial probit variable requires one for each alternative. As before, the observed dependent variables for multinomial probit equations are dummies collectively indicating which alternative is chosen. Since the multinomial probit link functions depend on several equations---an outcome depends on the utilities of all alternatives---each $g_j()$ is allowed to depend on all of ${\bf y}^*$, not just $y_j^*$.

To state the likelihood for observation $i$ in this model in a way that embraces all the individual models stated in \ref{subsec:single models}, we need a mathematical form that encompasses the likelihoods displayed earlier. It must allow truncation, probability functions that mix continuous and discrete components, and linear pre-transformation of the data (as in multinomial probits). For economy of presentation, gather unknown censoring points for ordered probits into a single vector ${\bf c}$. To express truncation, let $\underline \tau_{ij}$ and $\bar \tau_{ij}$ be the lower and upper truncation bounds for $y_j$; they take infinite values if there is no truncation (truncation is irrelevant in probit and multinomial probit models, for instance). The overall truncation range, the region of possible values of ${\bm \varepsilon}$ that could generate observable values for ${\bf y}$ given $\bf x$, is the Cartesian product
\begin{align}
T_i=\left[\underline \tau_{i1}-\theta_{i1},\bar \tau_{i1}-\theta_{i1}\right] \times \hdots \times \left[\underline \tau_{iJ}-\theta_{iJ},\bar \tau_{iJ}-\theta_{iJ}\right].
\label{Cartesian T}
\end{align}
In addition, let $m$ be the number of multinomial probit variables (thus multinomial equation groups) in the model, ${\tilde J}$ be $J-m$, and ${\bf M}_i$ be the ${\tilde J} \times J$ matrix that when left-multiplied with ${\bf y}^*$ and ${\bf x}$ subtracts the data for the multinomial probit equations for chosen alternatives from the corresponding rejected ones while leaving data for non-multinomial-probit equations untouched. ${\bf M}_i$ is block-diagonal, with blocks analogous to that in \eqref{M_k} for multinomial probit equation groups and ``blocks" that are simply $1$ for equations of other types. As in the multinomial probit discussion, we define ${\bf {\tilde y}}^*_i={\bf M_i y}^*$, ${\bm {\tilde \theta}}_i={\bf M_i}{\bm \theta}$, ${\bm {\tilde \varepsilon}}_i={\bf M_i}{\bm \varepsilon}$, ${\bm {\tilde \Sigma}}_i=\operatorname{Var}\left[{\bm {\tilde \varepsilon}}_i\right]={\bf M}_i{\bm \Sigma}{\bf M}_i'$, ${\tilde T}_i={\bf M}_i T_i$, and ${\bf {\tilde g}}()$ as the link function implied by ${\bf g}()$ from the space of ${\bf M}_i$-transformed errors to outcomes. Then the general observation-level likelihood is given by
\begin{align}
f_{{\bm {\tilde \varepsilon}}_i} \left( {\bf u} \right) &= \phi \left( {{\bf u};{\bm {\tilde \Sigma} }_i} \right) \notag \\
{\bf {\tilde h}}_i\left({\bm {\tilde \varepsilon}}_i\right) &= {\bf {\tilde g}}_i\left( {\bm {\tilde \theta}}_i + {\bm {\tilde \varepsilon}}_i \right) \notag \\
L_i\left({\bf B},{\bm \Sigma}, {\bf c};{\bf y}_i|{\bf x}_i\right)&= \frac
{\displaystyle{\int\limits_{{\bf {\tilde h}}^{ - 1}_i\left( {\bf y}_i \right)} {f_{{\bm {\tilde \varepsilon}}_i} \left( {\bm {\tilde \varepsilon}} \right){\bm {d {\tilde \varepsilon}}}}}}
{\displaystyle{\int\limits_{\tilde T_i} {f_{{\bm {\tilde \varepsilon}}_i} \left( {\bm {\tilde \varepsilon}} \right){\bm {d {\tilde \varepsilon}}}}}}.
\label{SUR likelihood}
\end{align}

The observation-level likelihood is the ratio of two integrals over certain regions of the distribution $f_{{\bm {\tilde \varepsilon}}_i}$, which is known given ${\bm \Sigma}$ and the outcomes of any multinomial choices. Both regions of integration have fairly simple forms: Cartesian products of line segments, rays, and lines (``Cartesian" for short). Since $T$ is unbounded in the dimensions corresponding to multinomial probit equations, transforming the space by ${\bf M}_i$ to produce ${\tilde T}$ merely deletes a few unbounded dimensions of $T$---one for each multinomial probit variable's chosen alternative in case $i$. So ${\tilde T}$ is the Cartesian product in \eqref{Cartesian T}, except deleting the components that correspond to these alternatives. Importantly, ${\bf {\tilde h}}^{ - 1}_i\left( {\bf y}_i \right)$ too is Cartesian, because the realization of one equation's error term for a given observation, $\varepsilon_{ij}$, does not affect the feasible range for another equation's. Thus ${\bf {\tilde h}}^{ - 1}_i\left( {\bf y}_i \right)$ is a Cartesian product of the types of domains defined in \eqref{OLS h inv}, \eqref{Tobit h inv}, \eqref{oprobit h inv}, and \eqref{mprobit h inv}:
\begin{align}
{\bf {\tilde h}}^{ - 1}_i\left( {\bf y}_i \right) = \left[ \underline c_{i1} - {\tilde \theta}_{i1}, \bar c_{i1} - {\tilde \theta}_{i1} \right] \times \hdots \times \left[ \underline c_{i\tilde J} - {\tilde \theta}_{i\tilde J}, \bar c_{i\tilde J} - {\tilde \theta}_{i\tilde J} \right].
\label{general h inv}
\end{align}
If $y_{ij}$ is uncensored, then $\underline c_{ij}=\bar c_{ij}$; in the censored case, either bound can be infinite.

\subsubsection{SUR examples}
The general likelihood above is formidable, but works out intuitively in elementary examples.

\vspace{10 mm}

\noindent Example 1. {\it Bivariate probit}

The model is
\begin{align*}
& y_1^* = \theta_1 + \varepsilon_1 \\
& y_2^* = \theta_2 + \varepsilon_2 \\
& \theta_1 = \beta_1x \\
& \theta_2 = \beta_2x \\
& {\bf y} = {\bf g}\left({\bf y}^*\right)=\left({\bf 1}\left\{y_1^*>0\right\},{\bf 1}\left\{y_2^*>0\right\}\right)'\\
& {\bm \varepsilon} = \left(\varepsilon_1,\varepsilon_2\right)' \sim \mathcal{N}\left({\bf 0},{\bm \Sigma}\right) \\
& {\bm \Sigma}=\left[ {\begin{array}{*{20}c}
   1 & \rho \\
   \rho & 1 \\
\end{array}} \right].
\end{align*}
The diagonal entries of ${\bm \Sigma}$ are 1 to normalize scale for both equations. With reference to the definitions in the previous section, since there are no multinomial probit equations, ${\bf M}$ is the identity matrix, and we can dispense with the $\sim$ hats. Since the model does not vary by observation, we can drop the $i$ subscripts. And because there is no truncation, the denominator of \eqref{SUR likelihood} is 1. We have:
\begin{align*}
f_{{\bm \varepsilon}} \left( {\bf u} \right) &= \phi \left( {{\bf u};\bm \Sigma} \right) \\
{\bf h}\left({\bm \varepsilon}\right) &= {\bf  g}\left( {\bm \theta} + {\bm \varepsilon} \right) \\
L_i\left(\beta_1,\beta_2,\rho;{\bf y}_i|{\bf x}_i\right)&=
\int\limits_{{\bf h}^{ - 1}\left( {\bf y}_i \right)} {f_{{\bm \varepsilon}} \left( {\bm \varepsilon} \right){\bm {d \varepsilon}}}.
\end{align*}
Suppose that we observe $y_{i1}=y_{i2}=0$. Then the space of possible values of the latent variables ${\bf y}^*_i$ is the quarter plane ${\bf g}^{ - 1}\left( {\bf y}_i \right)=\left(-\infty, 0\right] \times \left(-\infty, 0\right]$ and the space of possible values for the errors ${\bm \varepsilon}_i$ is the quarter plane ${\bf h}^{ - 1}\left( {\bf y}_i \right)=\left(-\infty, -\theta_{i1}\right] \times \left(-\infty, -\theta_{i2}\right]$. Integrating the probability distribution over this Cartesian range gives us the likelihood for this particular pair of outcomes:
\begin{align}
L_i\left(\beta_1,\beta_2,\rho;{\bf y}_i|{\bf x}_i\right)= \int_{-\infty}^{-\theta_{i1}}{\int_{-\infty}^{-\theta_{i2}}{\phi \left( \left(\varepsilon_1,\varepsilon_2 \right)';{\bm \Sigma}\right) d \varepsilon_2 d \varepsilon_1}} =
\Phi \left( \left(-\theta_{i1},-\theta_{i2} \right)';{\bm \Sigma}\right).
\label{bivariate probit 0,0 likelihood}
\end{align}
Similarly, if ${\bf y}_i=\left(1,1\right)'$, the likelihood is $\int^{\infty}_{-\theta_1}{\int^{\infty}_{-\theta_2}{\phi \left( \left(\varepsilon_1,\varepsilon_2 \right)';{\bm \Sigma}\right) d \varepsilon_2 d \varepsilon_1}}$, which by the symmetry of the normal distribution is $\Phi \left( \left(\theta_{i1},\theta_{i2} \right)';{\bm \Sigma}\right)$
In general, it works out that
\begin{align}
L_i\left(\beta_1,\beta_2,\rho;{\bf y}_i|{\bf x}_i\right) = \Phi \left( \left(q_1\theta_{i1},q_2\theta_{i2} \right)';{\bm \Sigma}\right) \text {, where } q_j=2y_{ij}-1.
\label{bivariate probit likelihood}
\end{align}

\vspace{10 mm}

\noindent Example 2. {\it A mixed probit-uncensored model}

We modify the previous example to illustrate how the likelihood works out in a model that mixes censored and uncensored variables. Equation 1 is classically linear while equation 2 is probit:
\begin{align*}
& y_1^* = \theta_1 + \varepsilon_1 \\
& y_2^* = \theta_2 + \varepsilon_2 \\
& \theta_1 = \beta_1x \\
& \theta_2 = \beta_2x \\
& {\bf y} = {\bf g}\left({\bf y}^*\right) = \left(y_1^*,{\bf 1}\left\{y_2^*>0\right\}\right)' \\
& {\bm \varepsilon} = \left(\varepsilon_1,\varepsilon_2\right)' \sim \mathcal{N}\left({\bf 0},{\bm \Sigma}\right) \\
& {\bm \Sigma}=\left[ \begin{array}{*{20}c}
   \sigma_{11} & {\sigma_{12} }  \\
   {\sigma_{12} } & 1  \\
\end{array} \right].
\end{align*}

Suppose that we observe some ${\bf y}_i=\left(y_{i1},0\right)'$. Then the space over which to integrate the probability distribution for the errors is ${\bf h}^{-1}\left( {\bf y}_i \right)=\left\{y_{i1}-\theta_{i1}\right\} \times \left(-\infty,-\theta_2\right]$, which is a one-dimensional ray within the plane. Integrating over this set,
\begin{align}
L_i\left(\beta_1,\beta_2, {\bm \Sigma};{\bf y}_i|{\bf x}_i\right) = \int_{-\infty}^{-\theta_2}{\phi \left( \left(y_{i1}-\theta_{i1},\varepsilon_2 \right)';{\bm \Sigma}\right) d \varepsilon_2}.
\label{mixed eg likelihood}
\end{align}

This formula is accurate, but impossible to compute directly using standard functions available in statistical software. To make it practical---and to illustrate how {\tt cmp} computes such mixed likelihoods---we need to factor $\phi\left(\cdot; {\bm \Sigma}\right)$ into probability distribution functions for $\varepsilon_1$ and $\varepsilon_2|\varepsilon_1$. Fortunately, the reproductive rules for the normal distribution generally boil down to linear algebra in mean vectors and covariance matrices. The rule we need is:

\newtheorem{lem}{Lemma}
\begin{lem}
(Conditional distribution of a multivariate normal distribution.) Let ${\bf u} \sim \mathcal{N}\left({\bf 0}, {\bm \Sigma}\right)$ be a random vector, ${\bf u}=\left({\bf u}_1',{\bf u}_2'\right)'$ be a partitioning of ${\bf u}$, and
\begin{align*}
\left[ {\begin{array}{*{20}c}
   {{\bm \Sigma}_{11} } & {{\bm \Sigma}_{12} }  \\
   {{\bm \Sigma}_{21} } & {{\bm \Sigma}_{22} }  \\
\end{array}} \right]
\end{align*}
be a conformable partitioning of ${\bm \Sigma}$. Then ${\bf u}_1 \sim \mathcal{N}\left({\bf 0}, {\bm \Sigma}_{11}\right)$  and
\begin{align*}
{\bf u}_2\left|{\bf u}_1\right. \sim \mathcal{N}\left({\bm \mu}_{2|1}, {\bm \Sigma}_{2 | 1} \right).
\end{align*}
where
\begin{align}
{\bm \mu}_{2 | 1} &= {\bm \Sigma}_{21}{\bm \Sigma}_{11}^{-1}{\bf u}_1 \\
{\bm \Sigma}_{2 | 1}&= {\bm \Sigma}_{22} -{\bm \Sigma}_{21}{\bm \Sigma}_{11}^{-1}{\bm \Sigma}_{12}. \notag
\label{perp def}
\end{align}
\end{lem}
\begin{proof}
The math here is that of linear projection, akin to OLS. ${\bm \mu}_{2 | 1}$, the expectation of ${\bf u}_2$ given ${\bf u}_1$, is
\begin{align*}
{\bm \mu}_{2 | 1} = {\bm \Sigma}_{21}{\bm \Sigma}_{11}^{-1}{\bf u}_1 = \operatorname{Cov}\left[{\bf u}_2,{\bf u}_1\right] \cdot \operatorname{Cov}\left[{\bf u}_1,{\bf u}_1\right]^{-1} {\bf u}_1 ;
\end{align*}
this is the orthogonal projection of ${\bf u}_2$ into ${\bf u}_1$ space.\footnote{Compare to the OLS projection ${\bf \hat Y} = {\bf X}\left( {{\bf X'X}} \right)^{ - 1} {\bf X'Y}$ or, transposing, ${\bf \hat Y'} = {{\bf Y'X}}\left( {{\bf X'X}} \right)^{ - 1} {\bf X'}.$} To see this, we check that the projection and ${\bf u}_2$'s deviation from it are orthogonal, having 0 covariance:
\begin{align*}
{\mathop{\rm Cov}\nolimits} \left[ {\bm \mu }_{2 | 1}, {\bf u}_2 - {\bm \mu }_{2 | 1}  \right] &= {\mathop{\rm Cov}\nolimits} \left[ {\bm \Sigma}_{21}{\bm \Sigma}_{11}^{-1}{\bf u}_1 ,{\bf u}_2  - {\bm \Sigma}_{21} {\bm \Sigma}_{11}^{ - 1} {\bf u}_1  \right] = {\bm \Sigma}_{21}{\bm \Sigma}_{11}^{-1}{\mathop{\rm Cov}\nolimits} \left[ {\bf u}_1 ,{\bf u}_2  \right] - {\bm \Sigma}_{21}{\bm \Sigma}_{11}^{-1}{\mathop{\rm Var}\nolimits} \left[ {{\bf u}_1 } \right]\left( {{\bm \Sigma}_{21} {\bm \Sigma}_{11}^{ - 1} } \right)'  \\
&= {\bm \Sigma}_{21}{\bm \Sigma}_{11}^{-1}{\bm \Sigma}_{12}  - {\bm \Sigma}_{21}{\bm \Sigma}_{11}^{-1}{\bm \Sigma}_{11} {\bm \Sigma}_{11}^{ - 1} {\bm \Sigma}_{12}  = {\bf 0}.
\end{align*}
And we check that ${\bm \Sigma}_{2 | 1}$ is the variance of the deviation of ${\bf u}_2$ around its conditional expectation:
\begin{align*}
{\mathop{\rm Var}\nolimits} \left[ {\bf u}_2  - {\bm \mu }_{2 | 1} \right] &=
{\mathop{\rm Cov}\nolimits} \left[ {\bf u}_2  - {\bm \mu }_{2 | 1} , {\bf u}_2  - {\bm \mu }_{2 | 1} \right] =
{\mathop{\rm Cov}\nolimits} \left[ {\bf u}_2  , {\bf u}_2  - {\bm \mu }_{2 | 1} \right] -
{\mathop{\rm Cov}\nolimits} \left[  {\bm \mu }_{2 | 1} , {\bf u}_2  - {\bm \mu }_{2 | 1} \right] \\
& =
{\mathop{\rm Cov}\nolimits} \left[ {\bf u}_2  , {\bf u}_2  - {\bm \mu }_{2 | 1} \right] - {\bf 0}
= {\mathop{\rm Var}\nolimits} \left[ {{\bf u}_2 } \right] - {\mathop{\rm Cov}\nolimits} \left[ {{\bf u}_2 ,\bm \Sigma_{21} \bm \Sigma_{11}^{ - 1} {\bf u}_1 } \right] = \bm \Sigma_{22}  - \bm \Sigma_{21} \bm \Sigma_{11}^{ - 1} \bm \Sigma_{12} = \bm \Sigma_{2 | 1}.
\end{align*}
Finally, as linear functions of the normal ${\bf u}$, ${\bf u}_1$ and ${\bf u}_2\left|{\bf u}_1\right.$ are themselves normal.
\qedhere
\end{proof}

For the model at hand, this formula for the conditional distribution of a normal distribution leads to the factoring
\begin{align*}
\phi\left(\left( \varepsilon_1,\varepsilon_2 \right);{\bm \Sigma}\right)=\phi \left(\varepsilon_1;\sigma_{11}\right)
\phi\left( \varepsilon_2-\frac{\sigma_{21}}{\sigma_{11}}\varepsilon_1; 1-\frac{\sigma_{21}\sigma_{12}}{\sigma_{11}}\right),
\end{align*}
where $\sigma_{21}=\sigma_{12}$.

Plugging this into \eqref{mixed eg likelihood},
\begin{align*}
L_i\left(\beta_1,\beta_2, {\bm \Sigma};{\bf y}_i|{\bf x}_i\right) &= \int_{-\infty}^{-\theta_2}{\phi \left(y_{i1}-\theta_{i1};\sigma_{11}\right)
\phi\left( \varepsilon_2-\frac{\sigma_{21}}{\sigma_{11}}\left(y_{i1}-\theta_{i1}\right); 1-\frac{\sigma_{21}\sigma_{12}}{\sigma_{11}}\right) d \varepsilon_2} \\
 &= \phi \left(y_{i1}-\theta_{i1};\sigma_{11}\right)\int_{-\infty}^{-\theta_2}{
\phi\left( \varepsilon_2-\frac{\sigma_{21}}{\sigma_{11}}\left(y_{i1}-\theta_{i1}\right); 1-\frac{\sigma_{21}\sigma_{12}}{\sigma_{11}}\right) d \varepsilon_2} \\
 &= \phi \left(y_{i1}-\theta_{i1};\sigma_{11}\right)\Phi\left( -\theta_2-\frac{\sigma_{21}}{\sigma_{11}}\left(y_{i1}-\theta_{i1}\right); 1-\frac{\sigma_{21}\sigma_{12}}{\sigma_{11}}\right).
\end{align*}
This product of a one-dimensional normal probability density and a one-dimensional cumulative normal density can be computed with standard functions in statistical software.

\subsubsection{Recursive systems}
\label{subsec:Recursive systems}
SUR systems are a special case of simultaneous-equation systems. In the larger class, endogenous variables can figure in each other's equations. Estimation in the broader framework is more complex, especially where there is censoring: a censored endogenous variable could influence other endogenous variables in either its latent or observed realization. {\tt cmp} does {\it not} include features to handle these complexities. {\tt cmp} is fundamentally an SUR estimation program. But it turns out that the ML SUR can consistently estimate parameters in an important subclass of mixed-process simultaneous systems: ones that are {\it recursive}, with clearly defined stages; and that are {\it fully observed}, meaning that endogenous variables appear on the right-hand side only as observed.

Recursive equation systems arise in two major ways. In the {\it full-information} case, the structural model is itself recursive and fully articulated (omitting no variables), and leads directly to a recursive set of equations that are the basis for ML estimation. In the more common {\it limited-information} case, only the final stage(s) are fully specified. Equations for earlier stages include instruments to address endogeneity; or, more generally, they omit influential variables. In this case, if the dependent variable(s) in the final stage are continuous and unbounded then simpler techniques such as 2SLS are consistent (Kelejian 1971). In addition, 2SLS and related linear methods are consistent in the presence of heteroskedasticity whereas ML estimation that explicitly models the censoring may not be, as discussed in section \ref{subsec:het} below. On the other hand, if the errors can be assumed to be identically (if not independently) distributed, a model that uses the information about limited nature of the earlier-stage dependent variables should be more efficient.

To be clear, the ML SUR framework works for fully observed recursive equation systems in the sense that simply inserting the observed endogenous variables into the vector of the predetermined variables, {\bf x}, in \eqref{SUR likelihood} yields likelihoods whose maximization generates consistent parameter estimates. This fact is not widely understood, except as it applies to the classical example of all dependent variables being linear.\footnote{E.g., Greene (1998, p. 202) writes ``surprisingly" and ``seem not to be widely known" in discussing the two-stage probit model.}

To fix ideas, we change the SUR model to
\begin{align}
& \mathop{{{\bf y}^*}'}\limits_{1 \times J}  = \mathop{{\bm \theta}'}\limits_{1 \times J} + \mathop{{\bm \varepsilon}'}\limits_{1 \times J} \\
& \mathop{{\bm \theta}'}\limits_{1 \times J}  = \mathop{{\bf y}'}\limits_{1 \times J} \mathop{\bm \Delta}\limits_{J \times J} + \mathop{{\bf x}'}\limits_{1 \times K} \mathop{\bf B}\limits_{K \times J} \notag \\
& {\bf y} = {\bf g} \left({\bf y}^* \right) = \left[ g_1 \left({\bf y}^* \right) \hdots g_J\left({\bf y}^*\right)\right]'. \notag \\
& {\bm \varepsilon}|{\bf x} \sim \text{i.i.d. } \mathcal{N}\left({\bm 0}, {\bm \Sigma}\right) \notag
\label{recursive model}
\end{align}
where ${\bf \Delta}$ is strictly upper triangular, meaning that the diagonal and the lower triangle are all 0's.

Just as in the SUR case, the likelihood for some observation $i$ is an integral over a region of the probability distribution of ${\bm \varepsilon}_i$, potentially divided by a second integral to account for truncation, as in \eqref{SUR likelihood}. For a seemingly inappropriate ML SUR estimator to compute this probability correctly despite treating ${\bf y}$ like ${\bf x}$ on the right, it must integrate the right distribution over the right regions. To demonstrate that it does, we want to factor the distribution at the heart of \eqref{SUR likelihood} in a way that conforms with the sequential structure of the model. Perhaps the best way to see this is with an example.

\vspace{10 mm}

\noindent Example 3. {\it Two-stage probit}

We modify the bivariate probit model in Example 1 in one way, adding ${y_1}$ to the  $y_2^*$ equation:
\begin{align*}
& y_1^* = \theta_1 + \varepsilon_1 \\
& y_2^* = \theta_2 + \varepsilon_2 \\
& \theta_1 = \beta_1 x \\
& \theta_2 = \delta y_1 + \beta_2 x \\
& {\bf y} = {\bf g}\left({\bf y}^*\right)=\left({\bf 1}\left\{y_1^*>0\right\},{\bf 1}\left\{y_2^*>0\right\}\right)' \\
& {\bm \varepsilon} = \left(\varepsilon_1,\varepsilon_2\right)' \sim \mathcal{N}\left({\bf 0},{\bm \Sigma}\right) \\
& {\bm \Sigma}=\left[ {\begin{array}{*{20}c}
   1 & \rho   \\
   \rho  & 1  \\
\end{array}} \right].
\end{align*}
Note that $\rho$ measures the endogeneity of $y_1$ in the $y_2^*$ equation. For if $\varepsilon_1$ is uncorrelated with $\varepsilon_2$, so is $y_1$, conditional on $x$.

Begin again by supposing that for some observation $i$, we observe ${\bf y}_i=\left(0,0\right)'$. As in Example 1, the feasible range for $\varepsilon_{i1}$ is $\left(-\infty,-\theta_{i1}\right]$. The distribution over this region is $f_{\varepsilon_1}\left(\varepsilon_1\right)=\phi\left(\varepsilon_1; \Sigma_{11}\right)$ where $\Sigma_{11}=1$. Conditioning on this realization of $\varepsilon_{i1}$, and given the resulting value of $y_{i1}$, the feasible range for $\varepsilon_{i2}$ is $\left(-\infty,-\theta_{i2}\right]$ and its distribution is $\mathcal{N}\left( \mu_{2| 1}, \Sigma_{2 | 1}\right)$, using the definitions in Lemma 1. So
\begin{align*}
L_i\left(\beta_1,\beta_2,\delta, \rho; {\bf y}_i|{\bf x}_i\right) &=
\int_{-\infty}^{-\theta_{i1}}f_{\varepsilon_1}\left(\varepsilon_1\right){\int_{-\infty}^{-\theta_{i2}}{f_{\varepsilon_2 | \varepsilon_1 }\left(\varepsilon_2\right) d \varepsilon_2}  d \varepsilon_1}.
\end{align*}
Because the bounds for the inner integral do not depend on the variable for the outer one---$y_{i1}$ is constant (at 0) over $\varepsilon_1\in\left(-\infty, -\theta_{i1}\right]$, so $\theta_{i2}= \delta y_{i1} + \beta_2 x_i$ is too---the domain of integration for the full, double integral is Cartesian, and we can write
\begin{align*}
L_i\left(\beta_1,\beta_2,\delta, \rho; {\bf y}_i|{\bf x}_i\right)&=
\int_{-\infty}^{-\theta_{i1}}{\int_{-\infty}^{-\theta_{i2}}{f_{\varepsilon_1}\left(\varepsilon_{i1}\right)f_{\varepsilon_2 | \varepsilon_1 }\left(\varepsilon_{i2}\right)d \varepsilon_2 d \varepsilon_1}}=
\int_{-\infty}^{-\theta_{i1}}{\int_{-\infty}^{-\theta_{i2}}{f_{{\bm \varepsilon}}\left({\bm \varepsilon}_i\right)d \varepsilon_2 d \varepsilon_1}} \\
&=\Phi \left( \left(-\theta_{i1},-\theta_{i2} \right)';{\bm \Sigma}\right).
\end{align*}

This likelihood equals that in \eqref{bivariate probit 0,0 likelihood}, except that here $\theta_{i2}$ is a linear combination of $y_{i1}$ as well as $x_{i2}$. Thus, adapting the SUR likeilhood by treating $y_1$ as an ordinary, predetermined regressor produces the correct LIML or FIML likelihood (Maddala and Lee (1976), p. 526; Maddala (1983), pp. 122--23). ML estimation with the likelihood is consistent in both cases and efficient in the latter.

\vspace{10 mm}

This example extends straightforwardly to the general fully observed recursive model:
\begin{align}
L_i\left({\bf B},{\bm \Sigma}, {\bm \Delta}, {\bf c};{\bf y}_i|{\bf x}_i\right)&= \frac
{\displaystyle{\int\limits_{{\bf {\tilde h}}^{ - 1}_i\left( {\bf y}_i \right)} {f_{{\bm {\tilde \varepsilon}}_i} \left( {\bm {\tilde \varepsilon}} \right){\bm {d {\tilde \varepsilon}}}}}}
{\displaystyle{\int\limits_{\tilde T_i} {f_{{\bm {\tilde \varepsilon}}_i} \left( {\bm {\tilde \varepsilon}} \right){\bm {d {\tilde \varepsilon}}}}}} \notag \\
&= \frac{\displaystyle{\int_{\underline{c}_1-{\tilde \theta}_{i1}}^{\bar{c}_1-{\tilde \theta}_{i1}}{f_{{\tilde \varepsilon}_1}\left({\tilde \varepsilon}_1\right) \int_{\underline{c}_2-{\tilde \theta}_{i2}}^{\bar{c}_2-{\tilde \theta}_{i2}} {f_{{\tilde \varepsilon}_2\left|{\tilde \varepsilon}_1\right.}\left({\tilde \varepsilon}_2\right) \hdots   \int_{\underline{c}_{\tilde J}-{\tilde \theta}_{i\tilde J}}^{\bar{c}_{\tilde J}-{\tilde \theta}_{i\tilde J}}{f_{{\tilde \varepsilon}_{\tilde J}\left|{\tilde \varepsilon}_1, \hdots, {\tilde \varepsilon}_{{\tilde J}-1}\right.}\left({\tilde \varepsilon}_{\tilde J}\right) d{\tilde \varepsilon}_{\tilde J} \hdots d{\tilde \varepsilon}_1}}}}}
{\displaystyle{\int_{\underline{\tau}_{i1}-{\tilde \theta}_{i1}}^{\bar{\tau}_{i1}-{\tilde \theta}_{i1}}{f_{{\tilde \varepsilon}_1}\left({\tilde \varepsilon}_1\right) \int_{\underline{\tau}_{i2}-{\tilde \theta}_{i2}}^{\bar{\tau}_{i2}-{\tilde \theta}_{i2}} {f_{{\tilde \varepsilon}_2\left|{\tilde \varepsilon}_1\right.}\left({\tilde \varepsilon}_2\right) \hdots   \int_{\underline{\tau}_{i\tilde J}-{\tilde \theta}_{i\tilde J}}^{\bar{\tau}_{i\tilde J}-{\tilde \theta}_{i\tilde J}}{f_{{\tilde \varepsilon}_{\tilde J}\left|{\tilde \varepsilon}_1, \hdots, {\tilde \varepsilon}_{{\tilde J}-1}\right.}\left({\tilde \varepsilon}_{\tilde J}\right) d{\tilde \varepsilon}_{\tilde J} \hdots d{\tilde \varepsilon}_1}}}}} \notag \\
&= \frac{\displaystyle{\int_{\underline{c}_1-{\tilde \theta}_{i1}}^{\bar{c}_1-{\tilde \theta}_{i1}}{\int_{\underline{c}_2-{\tilde \theta}_{i2}}^{\bar{c}_2-{\tilde \theta}_{i2}} { \hdots   \int_{\underline{c}_{\tilde J}-{\tilde \theta}_{i\tilde J}}^{\bar{c}_{\tilde J}-{\tilde \theta}_{i\tilde J}}{f_{\bm {\tilde \varepsilon}}\left({\bm {\tilde \varepsilon}}\right) d{{\bm {\tilde \varepsilon}}}}}}}}
{\displaystyle{\int_{\underline{\tau}_{i1}-{\tilde \theta}_{i1}}^{\bar{\tau}_{i1}-{\tilde \theta}_{i1}}{\int_{\underline{\tau}_{i2}-{\tilde \theta}_{i2}}^{\bar{\tau}_{i2}-{\tilde \theta}_{i2}} { \hdots   \int_{\underline{\tau}_{i\tilde J}-{\tilde \theta}_{i\tilde J}}^{\bar{\tau}_{i\tilde J}-{\tilde \theta}_{i\tilde J}}{f_{\bm {\tilde \varepsilon}}\left({\bm {\tilde \varepsilon}}\right) d{{\bm {\tilde \varepsilon}}}}}}}}
\end{align}
where $f_{\bm {\tilde \varepsilon}}\left({\bm {\tilde \varepsilon}}\right)=\phi\left({\bm {\tilde \varepsilon}}; {\bm {\tilde \Sigma}}\right)$. Again, this matches the SUR likelihood with ${\bm \theta}$ redefined to treat ${\bf y}$ on the right as if it is predetermined.

\subsubsection{Conditional modeling}
The setting for almost all the theoretical discussion so far has been a single observation. This focus is deliberate, for it leaves open the possibility that the model can vary by observation, i.e., depend on the data. A model that is conditional on the data can seem strange to minds accustomed to the rigidity of OLS, 2SLS, and other GMM-class estimators. But it is possible in ML, and useful. {\it Parameters} cannot vary so freely (or they might not be identified), but choices of model structure, such as the number of equations, the form of their link functions, and the location of known truncation and censoring points, can. For example, in an evaluation of a worker retraining program, an equation for the determinants of uptake could be dropped for observations in cities where the program was not offered. The consistency of SUR likelihoods for fully observed recursive systems is unaffected by this generalization.

Two examples of conditional modeling deserve special mention. One is the switching regression: it can incorporate two or more models for the same dependent variable, with the data determining which one applies to which observations, and can be viewed as a system of equations whose samples do not overlap. The other example is selection modeling. The classical Heckman selection model is like that of Example 2, except that $y_1$, the variable of interest, is only modeled when $y_2$, the dummy indicating whether the observation is complete, is 1. For complete observations, the likelihood is \eqref{mixed eg likelihood}. For incomplete observations, the likelihood is just that for a one-equation probit model. The overall likelihood is the product of the observation-level ones.

These two ideas can be combined: a variable that drives a switching process can itself be modeled with a ``selection" equation. An ordered categorical variable, for example, can be modeled as ordered probit while determining which of several models for a variable of interest apply, as in the {\tt oheckman} command (Chiburis and Lokshin 2007).

All of these examples can be seen as instances of a single, general modeling framework. Interestingly, Heckman's (1976) seminal paper on selection modeling is entitled ``The common structure of statistical models of truncation, sample selection, and limited dependent variables and a simple estimator for such models."

\subsubsection{Heteroskedasticity and consistency}
\label{subsec:het}
One virtue of linear methods such as OLS and 2SLS is that heteroskedasticity harms only their efficiency, not their consistency. Heteroskedasticity does render the classical formulas for the standard errors of these estimators inconsistent, but several methods are available for correcting that problem, including bootstrapping and ``robust'' sandwich-type formulas.

Heteroskedasticity is a more serious threat to the limited dependent variable models considered here. The problem can be explained both graphically and analytically (Deaton 1997, pp. 85--89). Suppose we model hours worked outside the home, and that, for those who do work, hours worked is in expectation a linear function of education with slope 1. Suppose that errors are normal so that the Tobit model in \eqref{Tobit model} is correct---except that $\sigma^2$, the variance of the error term, is not constant, and is instead convexly, positively related to education. So high is the variance for highly educated people, we assume, that they are particularly likely to have extreme employment propensities ($y^*$), whether positive and negative. The disproportionate censoring of the {\it negative} values for highly educated people will increase their apparent tendency to work and bias upward the estimated slope of the relationship for uncensored observations. Figure \ref{fig:het-tobit} illustrates. The values of $y^*$ are plotted as solid diamonds and censored observations of $y$ as hollow ones. The solid line segments show the true regression model, $\operatorname{E}\left[y\left|x\right.\right]=x\cdot {\bf 1} \left\{x>0\right\}$. But high variance in the errors on the right end of the graphed range (according to $\sigma=1+\frac{(x+25)^{1.8}}{50}$) generates a cluster of large, negative values for $y^*$. These are censored upward, to 0, while the high positive values of $y^*$ in the same region are not symmetrically censored downward. As a result, their presence steepens the best-fit line for uncensored observations (dashed line), making the Tobit fit inconsistent.

More formally, it can be checked that the classical linear regression likelihood \eqref{OLS LL} has the property that when its first derivatives are 0 (at an optimum) the second-order cross derivative between $\bm \beta$ and $\sigma^2$ is too. So, at an optimum, an infinitesimal change in the best-fit value for $\sigma^2$ does not perturb the first derivative of the likelihood with respect to $\bm \beta$ from its value of 0. The first-order condition for $\bm \beta$ being an optimal value remains satisfied. In this sense, the ML estimate of $\bm \beta$ and that of $\sigma^2$ are independent; and the first remains consistent even when the latter, under heteroskedasticity, is not. In contrast, the Tobit likelihood in \eqref{Tobit LL}, with its novel term involving a cumulative normal density, lacks this property.

Technically, heteroskedasticity can also afflict more-completely censored models, such as probit. But here the problem is best thought of differently, and is perhaps less of a practical concern. Consider, as Deaton suggests, a probit model like that in \eqref{Probit model} except with heteroskedasticity that happens to take the peculiar form $\sigma=\bf x'\bm \beta/\bf x'\bm \gamma$, where $\bm \gamma$ is a coefficient vector. The likelihood for an observation with $y_i=1$ would then be
\begin{align*}
\Phi \left( {{{\bf x}'_i\bm\beta };\sigma^2 } \right) = \Phi \left( {\frac{{{\bf x}'_i\bm\beta }}{\sigma };1} \right) = \Phi \left( {\frac{{{\bf x}'_i\bm\beta }}{{{{{\bf x}'_i\bm\beta } \mathord{\left/
 {\vphantom {{{\bf x}'_i\bm\beta } {{\bf x}'_i\bm\gamma }}} \right.
 \kern-\nulldelimiterspace} {{\bf x}'_i\bm\gamma }}}};1} \right) = \Phi \left( {{\bf x}'_i\bm\gamma ;1} \right)
\end{align*}
Probit estimates of $\bm\beta$ would be consistent for $\bm\gamma$ instead! This again shows the inseparability of the location and dispersion parameters ($\bm\beta$ and $\sigma^2$) in limited dependent variable models.

The problem needs to be viewed in larger perspective, however (Wooldridge 2002, pp. 479--80). The model for $y^*$ is a mathematical convenience, a hypothetical equation for a hypothetical variable. Consider that if the true process for $y^*$ is that implied by the logit model then probit is technically inconsistent, and vice versa. Probably in most cases, neither model is perfectly correct, yet both are useful. From this point of view, heteroskedasticity is just one of possible deviations of the probit model from reality, one more potential imperfection in a chosen functional form. Meanwhile, because censoring in the probit model is more symmetric than in the censored-from-below Tobit model, the potential for systematic bias may be smaller.

Note two points the foregoing does {\it not} imply. First, correlations in errors across observations do not cause the same trouble. For consistency, errors need to be identically, but not necessarily independently, distributed. Second, moving to the multi-equation context, heteroskedasticity in one equation does not necessarily render coefficient estimates for other equations inconsistent. For example, if the heteroskedasticity is confined to the reduced-form equations in a LIML estimation set-up, the ones not required to be structurally correct, this may not harm the consistency of the parameter estimates for the structural equations (Anderson and Rubin 1950). Rather, modeling a reduced-form heteroskedastic error term as homoskedastic would be one more example of ``limited information" about the true model.\footnote{I have not worked out, nor seen worked out, the precise conditions under which heteroskedasticity in one equation affects the consistency of coefficient estimates for another.}

\begin{figure}
\caption{Example of heteroskedasticity-induced inconsistency in Tobit model}
\label{fig:het-tobit}
\includegraphics[width=6.5in]{het-tobitbw}
\end{figure}
\subsubsection{Logical consistency and identification}
The conditions for the consistency of ML SUR for simultaneous equations---recursivity and full observability---are less strict than they appear, in the sense that many models that one could write down that violate one or both restrictions are in fact logically impossible (Maddala and Lee 1976; Heckman 1978). For example, a fully observed multivariate probit model {\it must} be recursive to be logically consistent (Schmidt 1981). A simple example of an impossible model is:
\begin{align*}
& y_1^* = \gamma_1 y_2 + \varepsilon_1 \\
& y_2 = \gamma_2 y_1+ \varepsilon_2 \\
& y_1 = {\bf 1}\left\{y_1^*>0\right\} \\
& {\bm \varepsilon} \sim \mathcal{N}\left({\bm 0}, {\bm \Sigma}\right)
\end{align*}
This mixed-process example is fully observed, but not recursive . Substituting for $y_2$ in the $y_1^*$ equation gives $y_1^* = \gamma_1 \gamma_2 y_1 + \gamma_1 \varepsilon_2 + \varepsilon_1$.
Combining this with the definition of $y_1$,
\begin{align*}
y_1 = 0 \text{ when } & \gamma_1 \varepsilon_2 + \varepsilon_1 \le -\gamma_1 \gamma_2 y_1 = 0 \\
y_1 = 1 \text{ when } & \gamma_1 \varepsilon_2 + \varepsilon_1 > -\gamma_1 \gamma_2 y_1 = -\gamma_1 \gamma_2.
\end{align*}
Thus, seemingly, depending upon the sign of $\gamma_1 \gamma_2$, if $\gamma_1 \varepsilon_2 + \varepsilon_1$ happens to be between 0 and $-\gamma_1 \gamma_2$, then $y_1$ would equal both 0 and 1---or neither. The model is logically consistent only if $-\gamma_1 \gamma_2=0$, i.e., if it is recursive.

The positive flip-side of the nonlinearity at work here is that multi-equation limited dependent variable models that are logically consistent often require fewer assumptions for formal identification than classical linear ones. For classical systems to be identified, a rank condition must be met. A common, though technically not quite sufficient, rule is the order condition: in each equation, at least one predetermined variable must be excluded for every endogenous one included (Greene 2000, p. 670). Surprisingly, such rules become less necessary as censoring introduces nonlinearities. For example, a fully observed multivariate probit model with unrestricted correlation error structure (which we just saw must be recursive) is in general identified without any further exclusion restrictions (Wilde 2000).

Consider the two-stage probit model in Example 3. Notice that the two equations share a single predetermined regressor, $x$. There is no ``instrument." The first-stage equation, a standard one-equation probit, is clearly identified. Wilde points out that the concern with regard to identification of the second is that some non-trivial linear combination of the two latent variables, $\lambda_1 y_1^* + \lambda_2 y_2^*, \lambda_1 \ne 0$, contains the same set of variables as the structural $y_2^*$ equation---that would be a sign of underidentification in an uncensored system. By the definition of the model, this linear combination is
\begin{align*}
\lambda_1 y_1^* + \lambda_2 y_2^* = \lambda_2\gamma y_1 + \lambda_1\beta_1 x + \lambda_2\beta_2 x + \lambda_1\varepsilon_1 +  \lambda_2\varepsilon_2.
\end{align*}
Thus,
\begin{align*}
y_2^* = \gamma y_1 - \frac{\lambda_1}{\lambda_2 } y_1^* + \frac{\lambda_1}{\lambda_2 }\beta_1 x + \beta_2 x + \frac{\lambda_1}{\lambda_2 }\varepsilon_1 +  \varepsilon_2.
\end{align*}
The first right-hand term is the same as in the structural equation, but it is followed by a new term containing $y_1^*$, so the equation as a whole is not redundant with the structural equation.

Wilde (2000) shows that a general (recursive) multi-equation probit model is identified as long as each equation contains one varying predetermined variable. This is akin the result cited in section \ref{subsec:Multinomial probit} that the unrestricted multinomial probit model is identified as long as one variable varies across alternatives. And here too, despite the theoretical results, identification might still be more robust if exclusion restrictions are imposed---that is, if the classical order condition, though theoretically unnecessary, is still met.

\section{Estimation}
\label{sec:Estimation}
The econometric literature on mixed-process models historically focused on multi-stage estimation procedures that are less computationally demanding than ML, if less efficient (e.g., Amemiya 1974; Heckman 1976; Maddala 1983, chs. 7--8; Smith and Blundell 1986; Rivers and Vuong 1988). This is one reason I have not found an encompassing discussion of ML estimation like that here. But faster computers have made direct ML fitting more practical. In particular, Monte Carlo-type simulated likelihood methods now facilitate estimation of integrals of multivariate normal distributions of dimension 3 and higher (Train 2003).

Given a general likelihood-maximizing tool such as Stata's {\tt ml}, the business of estimating parameters in the models described in this paper boils down to writing a program to compute the log of the likelihood \eqref{SUR likelihood} for each observation (and, optionally for speed, its first and even second derivatives). In general, an observation of ${\bf y}$ might not be censored in all dimensions, as in Example 2, so that the dimensionality of the integrals may be lower than the number of equations. These likelihoods are most practically calculated just as in that example, by factoring the uncensored dimensions out of the overall distribution. In particular, if we order equations to put the uncensored observations before the censored ones and partition ${\tilde {\bm \varepsilon}}$ and ${\bm {\tilde \Sigma}}$ accordingly, the numerator of the likelihood \eqref{SUR likelihood} can be calculated as
\begin{align*}
\phi \left({\tilde {\bm \varepsilon}}_1;{\bm {\tilde \Sigma}}_{11}\right)\int\limits_C{\phi\left( {\tilde {\bm \varepsilon}}_2 - {\bm {\tilde \Sigma}}_{21}{\bm {\tilde \Sigma}}_{11}^{-1} {\tilde {\bm \varepsilon}}_1;
{\bm {\tilde \Sigma}}_{22} -{\bm {\tilde \Sigma}}_{21}{\bm {\tilde \Sigma}}_{11}^{-1}{\bm {\tilde \Sigma}}_{12} \right) d {\tilde {\bm \varepsilon}}_2}.
\end{align*}
where $C$ is the Cartesian region of feasible values for ${\tilde {\bm \varepsilon}}_2$. Web Appendix A sets forth formulas and algorithms for computing the log of this likelihood and its first derivatives.

{\tt cmp} works like most ML estimation programs in Stata (Gould, Pitblado, and Sribney 2006). A front end processes the command line and prepares for estimation by {\tt ml}. To choose a promising starting point for the search, it first estimates each equation separately. It also performs several specification checks to improve the odds of convergence. For example, it drops collinear regressors, and detects whether any equations have non-overlapping samples, which should force the correlation parameter between their errors out of the model.

A separate program, also written in Stata's ado language and called repeatedly by {\tt ml}, computes the likelihood associated with a provided set of trial parameter values. This evaluator in turn calls a Mata program to perform most of the computations. To make results easier to interpret, {\tt cmp} represents ${\bm \Sigma}$ in ``sigma-rho" form, that is, with a standard deviation ($\sigma$) parameter for each error and a correlation coefficient ($\rho$) for each pair. Since these parameters are bounded, they are transformed onto an unbounded scale by using the logarithm of the $\sigma$'s and the arc-hyperbolic tangents (inverse S-curve transforms) of the $\rho$'s. Fitting with ``lnsig" and ``atanhrho" parameters eliminates the possibility that in the course of its search, {\tt ml} will submit impossible trial values for the parameters, such as a negative value for a $\sigma$.

Two aspects of {\tt cmp}'s workings are novel enough to warrant more discussion: the implementation of the Geweke, Hajivassiliou, and Keane (GHK) algorithm to compute higher-dimensional cumulative normal distributions, and the form of the likelihood evaluator. Both are designed to speed up {\tt cmp}. Because ML estimation is computationally expensive, speed increases practicality.

\subsection{{\tt ghk2()}}
\label{subsec:ghk2}
For models in which three or more equations are censored at once for some observations, cumulative normal densities of dimension 3 or higher must be estimated. This is not a trivial problem. For explanations of the dominant approach to this problem, the GHK algorithm (Geweke 1989; Hajivassiliou and McFadden 1998; Keane 1994), see Greene (2000, pp. 183--85), Cappellari and Jenkins (2003), and Gates (2006). The GHK algorithm estimates the cumulative probability with a Monte Carlo technique, taking a number of draws from the unit interval. The draws can come from a pseudorandom sequence, which is designed to minimize correlation between successive entries. Or they can come from Halton or Hammersley sequences; these are designed to maximize uniformity of coverage over the unit interval (Drukker and Gates 2006). (``Generalized Halton" sequences can be seen as Halton sequences with pseudorandom starting points.) Stata 9 shipped with the Mata function {\tt ghk()}, which computes the necessary draws every time it is called. With Stata 10 came {\tt ghkfast()}, which allows Stata to compute the draws once, for speed.

For implementation of {\tt cmp}, these built-in functions had several disadvantages. The Mata function {\tt ghk2()}, which {\tt cmp} requires, addresses the limitations (though not without introducing some disadvantages of its own). The major differences between {\tt ghk2()} and the built-in functions are:

\begin{enumerate}
      \item {\tt ghk2()} accepts lower as well as upper bounds for integration. This allows efficient estimation of
        cumulative probabilities over bounded rectilinear regions such as $\left[ \underline c_1, \bar c_1 \right] \times \left[\underline c_2 , \bar c_2\right]$, which arise in multi-equation ordered probit models. Without this ability, the routine would
        need to be called $2^d$ times, where $d$ is the dimension of the integral. For example, an integral of $\phi\left(\cdot; {\bm \Sigma}\right)$ over the rectangle above would have to be computed as $\Phi\left(\left(\bar c_1, \bar c_2 \right)'; {\bm \Sigma}\right) - \Phi\left(\left(\bar c_1, \underline c_2 \right)'; {\bm \Sigma}\right) - \Phi\left(\left(\underline c_1, \bar c_2 \right)'; {\bm \Sigma}\right) + \Phi\left(\left(\underline c_1, \underline c_2 \right)'; {\bm \Sigma}\right)$.\footnote{Actually, the built-in {\tt biprobit()} function would compute these four two-dimensional integrals much faster than a GHK implementaiton. The real utility is for higher-dimensional integrals.}

      \item {\tt ghk2()} does not ``pivot" the bounds of integration. On the recommendation of Genz (1992), {\tt ghk()} and {\tt ghkfast()}, at least by default, reorder
        each vector of bounds to put the larger entries toward the end, which turns out to increase the precision of the simulated probability. However,
        pivoting has the disadvantage of creating discontinuities in results. Small changes in the bounds that shuffle their rank ordering---e.g., from $\left(.999, 1.000\right)'$ to $\left(1.001, 1.000\right)'$---can produce relatively large changes
        in return values. Especially when the number of draws is low and the approximations coarse, these discontinuities
        can stymie a maximum likelihood search algorithm. Thus {\tt ghk2()} behaves smoothly even at low draw counts, at the expense of some precision. After {\tt ghk2()} was released, Stata Corporation added an option to {\tt ghk()} and {\tt ghkfast()} to turn off pivoting, in Stata 10.1.

      \item {\tt ghk2()} is optimized for contexts with a large
        number of observations relative to draws per observation. In extreme cases, such as 10,000 observations and 10 draws per observation, it can perform an order of
        magnitude faster than {\tt ghkfast()}. But at the opposite extreme, with, say, 100 observations and 1,000 draws per observation, it can run half as fast.

\end{enumerate}

Taking lower as well as upper bounds complicates the computation of the simulated probability as well as its derivatives with respect to the parameters---which {\tt ghk2()}, like the built-in functions, optionally provides. Web Appendix B lays out the relevant formulas.

\subsection{A new {\tt ml} evaluator type}
As mentioned, Stata's {\tt ml} performs the maximum likelihood search for {\tt cmp}, calling on a {\tt cmp} subprogram to calculate the log likelihood for each trial
    parameter vector. {\tt ml} accepts several types of likelihood evaluation routines. The simplest from the programmer's point of view is the {\tt lf} method, so-called because it is appropriate for likelihoods, like those here, that satisfy the linear form restriction: the overall log likelihood is the sum of observation-level log likelihoods, ones that can be computed using only a given observation's data. (As a counterexample, random effects models do not have linear form because their formulas irreducibly involve clusters of observations.) {\tt ml} provides an {\tt lf} evaluator with trial values for $\theta_j = {{\bf x}_j}'{\bm \beta}_j$ for each linear component of a model, as well as for ancillary parameters such as elements of ${\bm \Sigma}$. The {\tt lf} evaluator calculates only the log likelihood; {\tt ml} computes the first and second derivatives numerically as needed for the search, via repeated calls to the evaluator. Numerical calculation of deriviates is usually slower than analytical calculation. But {\tt ml} at least partly compensates for this computational inefficiency by exploiting the linear nature of the $\theta_j$ parameters. Since
\begin{align*}
\frac{{\partial \ln L_i }}{{\partial \bm \beta_j }} = \frac{{\partial \ln L_i }}{{\partial \theta_j }}\frac{{\partial \theta_j }}{{\partial {\bm \beta}_j }} = \frac{{\partial \ln L_i }}{{\partial \theta_j }}{\bf x}_j',
\end{align*}
    to obtain the vector $\displaystyle{\frac{{\partial \ln L_i }}{{\partial \bm \beta_j }}}$, {\tt ml} need only use the evaluator to calculate the scalar $\displaystyle{\frac{{\partial \ln L_i }}{{\partial \theta_j }}}$, which typically requires two calls to it (at the trial point and at that point plus or minus some small $h$ along the equation's dimension). That is, {\tt ml} calls the evaluator twice for each ${\bm \beta}_j$ rather than twice for each element of each ${\bm \beta}_j$. Similarly, the number of calls to compute the Hessian of the likelihood is quadratic in the number of linear components (plus ancillary parameters) rather than in the full number of parameters (Gould, Pitblado, and Sribney 2006, pp. 63--64). (Confusingly, this is {\it not} why the method is called ``linear form.")

    {\tt ml} also accepts {\tt d0}-, {\tt d1}-, and {\tt d2}-method evaluators. These do not assume linear form and they do not perform the trick just described to economize on numerical computation of derivatives. They do, however, allow the evaluator to compute these derivatives analytically. {\tt d1} evaluators calculate first derivatives while {\tt d2} evaluators do those and the Hessian. The odd thing about this arrangement is that moving from {\tt lf} to {\tt d1} imposes two independent changes on the programmer: ability to provide analytical first derivatives; and loss of the clever method of computing the Hessian that minimizes calls to the evaluator. Yet since these two changes are independent, the trade-off they create is theoretically unnecessary for linear-form likelihoods and could be avoided by a new evaluator type that blends the advantages of {\tt lf} and {\tt d1}. The trade-off affects the performance of {\tt cmp} because its likelihoods are in linear form and it computes first, but not second, derivatives analytically.

    Richard Gates and Jeffrey Pitblado of Stata Corporation suggested a work-around: write a ``pseudo-{\tt d2}" evaluator that takes full control of the process for computing first and second derivatives. A ``pseudo-{\tt d2}" evaluator computes first derivatives analytically, and second derivatives numerically, but with two calls to the evaluation code per linear component rather than per parameter. That is how {\tt cmp} works by default. Tests with one real-world example, a replication of the headline regression in Pitt and Khandker (1998), showed ``pseudo-{\tt d2}" with {\tt ml}'s Newton-Raphson search method running twice as fast as the next-best alternative, {\tt d1} with a Davidon-Fletcher-Powell search.

\section{Using {\tt cmp}}
\label{sec:cmp}
\subsection{Syntax for {\tt cmp}}
\label{subsec:syntax}
{\tt cmp} runs in Stata 9.2 and later. The syntax is \singlespacing
\begin{stsyntax}
cmp {\it eq} \optional{{\it eq} ...} \optif\ \optin\ \optweight\ , \dunderbar{ind}icators({\it exp} \optional{{\it exp} ...}) \optional{lf \dunderbar{nolr}test \dunderbar{qui}etly \dunderbar{ghkd}raws(\#) \dunderbar{ghkt}ype(\ststring) \dunderbar{ghka}nti \dunderbar{nodr}op level(\#) {\it ml\_opts} svy {\it svy\_opts} \dunderbar{inter}active init({\it vector}) \dunderbar{noest}imate \dunderbar{struc}tural \dunderbar{ps}ampling(\# \#)}
\end{stsyntax}\doublespacing

\noindent Each {\it eq} is an equation to be estimated, defined according to the {\tt ml model} {\it eq} syntax. That is, the equation is enclosed in parentheses, optionally prefixed with a name for the equation:
\singlespacing\begin{stsyntax}
            (\optional{{\it eqname}:} {\it varname\_y} \optional{{\it varname\_y2}} = \optindepvars\ \optional{, \dunderbar{nocons}tant \dunderbar{off}set({\it varname\_o)} \dunderbar{exp}osure({\it varname\_e})  \dunderbar{trunc}points({\it exp exp})})
\end{stsyntax}\doublespacing
\noindent {\it varname\_y2} is included only for interval-censored data, in a syntax analogous to that of {\tt intreg}: {\it varname\_y} and {\it varname\_y2} hold the lower and upper bounds of each interval. \dunderbar{trunc}points({\it exp exp}) is included only for truncated regressions, and specifies any lower and upper truncation points as constants, variable names, or expressions. Missing values in these variables or expressions (``.") are interpreted as $-\infty$ or $\infty$ as appropriate.

Since {\tt cmp} is built on {\tt ml}, it accepts most of the options that {\tt ml model} accepts in its non-interactive mode. See \rref{ml}. It accepts the {\tt svy} prefix, all weight types, {\tt constraints()}, the search {\tt technique()} option, and a variety of standard error types ({\tt robust}, {\tt cluster()}, etc.). Note that if the errors are not believed to be i.i.d. (and yet the estimation is constistent, under circumstances discussed at the end of section \ref{subsec:het}), then the {\tt cmp} likelihood is not fully accurate. The likelihood maximized is then a {\it pseudolikelihood}, and is labeled as such.

For estimates requiring the GHK algorithm, if a pseudorandom ({\tt ghktype(random)}) or
    generalized Halton sequence ({\tt ghktype(ghalton)}) is requested, the starting state of the Stata random number generator influences the values returned by
    {\tt ghk2()}, thus those returned by {\tt cmp}. For exact reproducibility of results with these sequences, initialize the seed to some chosen value with the {\tt set seed}
    command before running {\tt cmp}. Also worth remembering is that each observation that requires GHK simluation is assigned its own sequence of draws in a manner that depends on the order of the observations in the data set. Exact reproduction thus also requires preserving the sort order of the data.

The required {\tt \dunderbar{ind}icators()} option is central to the use of {\tt cmp}. Each {\it exp} in the option is an expression that evaluates to a {\tt cmp} {\it indicator variable}, which communicates observation-level
information about the dependent variable(s). The option must include one indicator variable for each equation in the model, and each can be a constant, a variable name, or a mathematical expression. Expressions can contain spaces or parentheses if they are double-quoted.
For each observation, each {\it exp} must evaluate to one of the following codes, with the meanings shown:

\singlespacing
0 = observation is not in this equation's sample; i.e., equation does not apply to this observation

1 = observation is uncensored

2 = observation is left-censored at the value stored in the dependent variable

3 = observation is right-censored at the value stored in the dependent variable

4 = equation is probit for this observation

5 = equation is ordered probit for this observation

6 = equation is multinomial probit for this observation

7 = equation is interval-censored for this observation

8 = equation is truncated on the left and/or right for this observation

\doublespacing

Notice that for a Tobit-modeled variable, it is the user's responsibility to determine and indicate in which observations the variable has been censored. The censoring point(s) can vary by observation. Also, as currently written, {\tt cmp} treats truncated regression as a distinct model type, so truncation cannot be combined with censoring. One complication in the syntax relates to the specification of multinomial probit models; see the Appendix.

For clarity, users can execute the {\tt cmp setup} subcommand, which defines global macros that can then be used in defining {\tt cmp} indicators:

\singlespacing
\begin{stlog}
\$cmp\_out = 0
\$cmp\_cont = 1
\$cmp\_left = 2
\$cmp\_right = 3
\$cmp\_probit = 4
\$cmp\_oprobit = 5
\$cmp\_mprobit = 6
\$cmp\_int = 7
\$cmp\_trunc = 8
\end{stlog}\doublespacing

\subsection{Options for {\tt cmp}}
\label{subsec:options}
\singlespacing
\hangpara {\tt \dunderbar{ind}icators({\it exp} \optional{\it {exp} ...})} is required, as just described.

\hangpara {\tt level(\#)} specifies the confidence level, in percent, for confidence intervals of the coefficients. The default is 95.

\hangpara {\tt \dunderbar{nolr}test} suppresses calculation and reporting of the likelihood ratio (LR) test of overall model fit, relative to
a constant(s)-only model. This has no effect if data are {\tt pweight}ed or errors are {\tt robust} or {\tt cluster}ed.
In those cases, the likelihood function does not reflect the non-sphericity of the errors, and so is a pseudolikelihood. The
LR test is then invalid and not run anyway.

\hangpara {\tt lf} makes {\tt cmp} use its {\tt lf}-method evaluator instead of its pseudo-{\tt d2} one. This is rarely needed.

\hangpara {\tt \dunderbar{qui}etly} suppresses much of the output: the results from any single-equation initial fits and the iteration log during the full model fit.

\hangpara {\tt init({\it vector})} passes a row vector of user-chosen starting values for the model fit, in the manner of the {\tt ml init, copy}
command. The vector must contain exactly one element for each parameter {\tt cmp} will estimate, and in the same order as {\tt cmp} reports the parameter estimates
in the output (excluding the displayed ``sig" and ``rho" results, which are merely transformed versions of the ``lnsig" and ``atanhrho" ones). The names of the row and columns of the vector do not matter.

\hangpara {\tt \dunderbar{noest}imate} simplifies the job of constructing an initial vector for the {\tt init()}
option. It instructs {\tt cmp} to stop before fitting the full model and leave behind
an e(b) return vector with one labeled entry for each free parameter. To view
this vector, type {\tt mat list e(b)}. You can copy and edit this vector, then pass it
back to {\tt cmp} with the {\tt init()} option.

\hangpara {\tt \dunderbar{inter}active} makes {\tt cmp} fit the model in {\tt ml}'s interactive mode.
This allows the user to interrupt the model fit by hitting Ctrl-Break or its equivalent, then view and adjust the trial solution with such
commands as {\tt ml plot}, then restart optimization by typing {\tt ml max}. {\tt cmp} runs more slowly in interactive mode.

\hangpara {\tt \dunderbar{ghkd}raws(\#)} sets the length of the sequence to draw for each observation in the GHK simulation of higher-dimensional cumulative multivariate normal distributions. The
default is twice the square root of the number of observations for which the simulation is needed. (Cappellari and Jenkins (2003) suggest the square root.)

\hangpara {\tt \dunderbar{ghkt}ype(\ststring)} specifies the type of sequence in the GHK simulation. Choices are ``halton" (the default), ``hammersley", ``random", and ``ghalton". See Drukker and Gates 2006; \mrefe{halton($\,$)}.

\hangpara {\tt \dunderbar{ghka}nti} requests antithetical draws, which doubles the number of draws. See Drukker and Gates 2006; \mrefe{halton($\,$)}.

\hangpara {\tt \dunderbar{struc}tural} requests the structural covariance parameterization for all multinomial equation groups, rather than the default differenced parameterization. See section \ref{subsec:Multinomial probit}.

\hangpara {\tt \dunderbar{nodr}op}: {\tt cmp} starts by fitting each equation separately in order to obtain a good starting point for the full model fit.  Sometimes in this preparatory step, convergence difficulties make a reported variance matrix singular, with missing standard errors for some
    regressors. Or variables can be found to be collinear. In order to maximize the chance of convergence, {\tt cmp} ordinarily drops such
    regressors from the equations in which they cause trouble. {\tt \dunderbar{nodr}op} prevents this behavior.

\hangpara {\tt \dunderbar{ps}ampling(\# \#)} makes {\tt cmp} perform what I call ``progressive sampling," which can speed estimation on large data sets. First it estimates on a small subsample, then a larger one, etc., until reaching the full sample. Each iteration uses the previous one's estimates as a starting point. The first argument in the option sets the initial sample size, either in absolute terms (if it is at least 1) or as a fraction of the full sample (if it is less than 1). The second argument is the factor by which the sample should grow in each iteration.

\hangpara {\it ml\_opts}: {\tt cmp} accepts the following standard {\tt ml} options: {\tt \dunderbar{tr}ace}, {\tt \dunderbar{grad}ient}, {\tt \dunderbar{hess}ian}, {\tt \dunderbar{sc}ore(}{\it newvarlist}{\tt |}{\it stub*}{\tt )}, {\tt \dunderbar{tech}nique(algorithm\_specs)}, {\tt vce(oim|\dunderbar{o}pg|\dunderbar{r}obust|\dunderbar{cl}uster)}, {\tt \dunderbar{iter}ate(\#)}, {\tt \dunderbar{const}raints(clist)},	 \\ {\tt \dunderbar{tol}erance(\#)},	 {\tt \dunderbar{ltol}erance(\#)}, {\tt \dunderbar{gtol}erance(\#)}, {\tt \dunderbar{nrtol}erance(\#)}, {\tt \dunderbar{nonrtol}erance}, {\tt \dunderbar{shownrt}olerance}, {\tt showstep}, and {\tt \dunderbar{dif}ficult}. See \rref{ml}.

\hangpara {\tt svy} indicates that {\tt ml} is to pick up the {\tt svy} settings set
by {\tt svyset} and use the robust variance estimator. This option
requires the data to be {\tt svyset}. {\tt svy} may
not be specified with {\tt vce()} or weights. See \svyref{svy:~estat}.

\hangpara {\it svy\_opts}: Along with {\tt svy}, users may also specify any of these {\tt ml} options, which affect how the {\tt svy}-based
variance is estimated:
	{\tt \dunderbar{nosvy}adjust},
	{\tt \dunderbar{sub}pop(}{\it subpop\_spec}{\tt )}, and
	{\tt \dunderbar{srs}subpop}. And users may specify any of these {\tt ml} options, which affect output display: {\tt deff},
	{\tt deft},
	{\tt meff},
	{\tt meft},
	{\tt \dunderbar{ef}orm},
	{\tt \dunderbar{p}rob}, and
	{\tt ci}. See \svyref{svy:~estat}.

\doublespacing
\subsection{On {\tt predict} and {\tt mfx} after {\tt cmp}}
The syntax of {\tt predict} following cmp is
\singlespacing
\begin{stsyntax}
    predict \optional{type} \{{\it newvarname}|{\it stub*}|{\it newvarlist}\} \optif\ \optin\ \optional{, {\it statistic} \dunderbar{eq}uation({\it eqno} \optional{,{\it eqno}}) \dunderbar{o}utcome({\it outcome}) \dunderbar{nooff}set}
\end{stsyntax} \doublespacing
\noindent where {\it statistic} is {\tt xb}, {\tt pr}, {\tt stdp}, {\tt stddp}, {\tt \dunderbar{sc}ores}, {\tt \dunderbar{re}siduals}, {\tt e({\it a b})}, or {\tt ystar({\it a b})}; and $a$ and $b$ may be numbers or variables, with any missing values interpret as infinite lower or upper ``bounds." These options mean:

\singlespacing\begin{tabular}{ll}
      {\tt xb}     &                  linear prediction \\
      {\tt stdp}    &                 standard error of linear prediction \\
      {\tt stddp}    &                standard error of difference in linear predictions \\
      {\tt \dunderbar{sc}ores}    &               derivative of the log likelihood with respect to a $\theta_j$ or an ancillary parameter \\
      {\tt \dunderbar{re}siduals}  &              residuals \\
      {\tt pr}                      & probability of a positive outcome (meant for probit and ordered probit equations) \\
      {\tt e({\# \#})}               &    censored expected value (see \rref{regress postestimation}) \\
      {\tt ystar({\# \#})}            &   truncated expected value (see \rref{regress postestimation}) \\
      & \\
      {\tt \dunderbar{eq}uation({\it eqno} \optional{,{\it eqno}})}   & specify equation(s) \\
      {\tt \dunderbar{o}utcome({\it outcome})}      &   specify outcome(s), for ordered probit only \\
      {\tt nooffset}          &       ignore any offset() or exposure() variable in the model \\
      &
\end{tabular}
\doublespacing

\noindent{\it eqno} can be an equation name. (If not set explicitly, an equation's name is that of its dependent variable.) Or it can be an
    equation number preceded by a {\tt \#}. Usually {\tt predict} will default to reporting statistics just for equation {\tt \#1}. However, it will generate statistics for all equations if the provided variable list has one entry for each equation, or
    takes the form {\it stub*}, with names as given or as automatically generated beginning with {\it stub}.

    In addition, for ordered probit equations, if {\tt pr} is specified, {\tt predict} will by default compute probability variables for all
    outcomes. The names for these variables will be automatically generated using a provided name as a stub. This stub may be directly provided in the command line---in which case it should {\it not} include a {\it *}---or may itself be automatically generated by a cross-equation {\it stub*}. Thus it is possible to generate probabilities for all outcomes in all ordered probit equations with a single, terse command. Alternatively, the {\tt outcome({\it outcome})} option can be used to request probabilities for just one outcome. {\it outcome} can be a value for the dependent variable, or a category number preceded by a {\tt \#}. For example, if the categorical dependent variable takes
    the values 0, 3, and 4, then {\tt outcome(4)} and {\tt outcome(\#3)} are synonyms.

    In explaining the multi-equation and multi-outcome behavior of {\tt predict} after {\tt cmp}, examples are worth a thousand words: see section \ref{subsec:predict examples}.

    The flexibility of {\tt cmp} affects the use of {\tt predict} and {\tt mfx} (for marginal effects) after estimation. Because the censoring type (probit, Tobit, etc.) can vary by observation, the default statistic for predict is always {\tt xb}, linear fitted values. So to obtain probabilities predicted by (ordered) probit equations, the user must include the {\tt pr} option in the predict command line or {\tt predict(pr)} in the {\tt mfx} command line. (For ordered probit equations, {\tt outcome()} option implies {\tt pr}.) And sometimes {\tt mfx}'s {\tt nonlinear} and {\tt force} options are required after {\tt cmp}.

\subsection{Examples}
\subsubsection{Replicating standard commands}
The purpose of {\tt cmp} is not to replicate existing commands, but to fit models that were previously much harder to estimate. Nevertheless, mimicking the familiar is a good way to illustrate how to use {\tt cmp}:

\singlespacing
\begin{stlog}
\end{stlog}
Set-up:
\begin{stlog}
cmp setup

webuse laborsup, clear
replace fem_inc = fem_inc - 10

\end{stlog}
OLS:
\begin{stlog}
reg kids fem_inc male_educ
cmp (kids = fem_inc male_educ), ind(\$cmp\_cont) quietly

\end{stlog}
Iterated SUR for a linear system (see Pagan (1979) on the equivalence of linear iterated SUR and ML SUR):
\begin{stlog}
sureg (kids = fem_inc male_educ) (fem_work = male_educ), isure
cmp (kids = fem_inc male_educ) (fem_work = male_educ), ind(\$cmp\_cont \$cmp\_cont) quietly

mvreg fem_educ male_educ = kids other_inc fem_inc
cmp (fem_educ = kids other_inc fem_inc) (male_educ = kids other_inc fem_inc), ind(\$cmp\_cont \$cmp\_cont) qui

\end{stlog}
Exactly identified linear two-stage (2SLS and LIML agree):
\begin{stlog}
ivregress 2sls fem_work fem_inc (kids = male_educ), first
ivregress liml fem_work fem_inc (kids = male_educ), first
cmp (fem_work = kids fem_inc) (kids = fem_inc male_educ), ind(\$cmp\_cont \$cmp\_cont) qui

\end{stlog}
Overidentified linear two-stage (2SLS and LIML differ):
\begin{stlog}
ivregress 2sls fem_work fem_inc (kids = male_educ other_inc), first
ivregress liml fem_work fem_inc (kids = male_educ other_inc), first
cmp (fem_work = kids fem_inc) (kids = fem_inc male_educ other_inc), ind(\$cmp\_cont \$cmp\_cont) qui

\end{stlog}
Probit:
\begin{stlog}
probit kids fem_inc male_educ
predict p
mfx
cmp (kids = fem_inc male_educ), ind(\$cmp\_probit) qui
predict p2, pr
mfx, predict(pr) nonlinear

\end{stlog}
Ordered probit:
\begin{stlog}
oprobit kids fem_inc male_educ
mfx, predict(outcome(#2))
cmp (kids = fem_inc male_educ), ind(\$cmp\_oprobit) qui
mfx, predict(pr outcome(#2)) nonlinear

\end{stlog}
Bivariate SUR probit:
\begin{stlog}
gen byte anykids = kids > 0
biprobit (anykids = fem_inc male_educ) (fem_work = male_educ)
cmp (anykids = fem_inc male_educ) (fem_work = male_educ), ind(\$cmp\_probit \$cmp\_probit)

\end{stlog}
Tetrachoric correlation of binary variables:
\begin{stlog}
tetrachoric anykids fem_work
cmp (anykids = ) (fem_work = ), ind($cmp_probit $cmp_probit) nolr qui

\end{stlog}
``IV-probit": first stage uncensored, second stage probit:
\begin{stlog}
ivprobit fem_work fem_educ kids (other_inc = male_educ), first
mfx, force predict(pr)
cmp (other_inc = fem_educ kids male_educ) (fem_work = other_inc fem_educ kids), ind(\$cmp\_cont \$cmp\_probit)
mfx, force predict(pr)

\end{stlog}
Treatment effects model with endogenous treatment: first stage probit, second stage uncensored:
\begin{stlog}
treatreg other_inc fem_educ kids, treat(fem_work  = male_educ)
cmp (fem_work  = male_educ) (other_inc = fem_educ kids fem_work), ind($cmp_probit $cmp_cont) qui

\end{stlog}
Tobit:
\begin{stlog}
tobit fem_inc kids male_educ, ll
cmp (fem_inc = kids male_educ), ind("cond(fem_inc, \$cmp\_cont, \$cmp\_left)") qui

\end{stlog}
``IV-Tobit": first stage uncensored, second stage Tobit:
\begin{stlog}
ivtobit fem_inc kids (male_educ = other_inc), ll first
cmp (male_educ=kids other_inc) (fem_inc=kids male_educ), ind(\$cmp\_cont "cond(fem_inc,\$cmp\_cont,\$cmp\_left)")

\end{stlog}
Interval regression:
\begin{stlog}
webuse intregxmpl, clear
intreg wage1 wage2 age age2 nev_mar rural school tenure
cmp (wage1 wage2 = age age2 nev_mar rural school tenure), ind(\$cmp\_int) qui

\end{stlog}
Truncated regression:
\begin{stlog}
webuse laborsub, clear
truncreg whrs kl6 k618 wa we, ll(0)
cmp (whrs = kl6 k618 wa we, trunc(0 .)), ind(\$cmp\_trunc) qui

\end{stlog}
Heckman selection model:
\begin{stlog}
webuse womenwk, clear
heckman wage education age, select(married children education age)
gen byte selectvar = wage<.
cmp (wage = education age) (selectvar = married children education age), ind(selectvar \$cmp\_probit) nolr qui

\end{stlog}
Probit with Heckman selection:
\begin{stlog}
gen byte wage2 = wage > 20 if wage < .
heckprob wage2 education age, select(married children education age)
cmp (wage2 = education age) (selectvar = married children education age), ind(selectvar*\$cmp\_probit \$cmp\_probit) qui

\end{stlog}

\subsubsection{Going beyond standard commands}
\begin{stlog}
webuse laborsup, clear

\end{stlog}
Regress an unbounded, continuous variable on an instrumented, binary one. 2SLS is consistent but less efficient:
\begin{stlog}
cmp (other_inc = fem_work) (fem_work = kids), ind(\$cmp\_cont \$cmp\_probit) qui robust
ivregress 2sls other_inc (fem_work = kids), robust

\end{stlog}
Now regress on a left-censored variable, female income, which is only modeled for observations in which the woman works:
\begin{stlog}
gen byte ind2 = cond(fem_work, cond(fem_inc, \$cmp\_cont, \$cmp\_left), \$cmp\_out)
cmp (other_inc=fem_inc kids) (fem_inc=fem_edu), ind(\$cmp\_cont ind2)

\end{stlog}
``IV-oprobit":
\begin{stlog}
cmp (fem_educ = fem_work) (kids = fem_educ), ind(\$cmp\_cont \$cmp\_oprobit) nolr

\end{stlog}
Ordered probit with Heckman selection modeling:
\begin{stlog}
webuse womenwk, clear
gen selectvar = wage<.
gen wage3 = (wage > 10)+(wage > 30) if wage < .
cmp (wage3 = education age) (selectvar = married children education age), ind(selectvar*\$cmp\_oprobit \$cmp\_probit) qui

\end{stlog}

\subsubsection{{\tt predict} after {\tt cmp}}
Set-up:
\begin{stlog}
webuse laborsup, clear

\end{stlog}
\label{subsec:predict examples}
\noindent Bivariate seemingly unrelated ordered probit:
\begin{stlog}
gen byte kids2 = kids + int(uniform()*3)
cmp (kids=fem\_educ) (kids2=fem\_educ), ind(\$cmp\_oprobit \$cmp\_oprobit) nolr tech(dfp) qui

\end{stlog}
Predict fitted values. Fitted values are always the default, as is equation \#1:
\begin{stlog}
predict xbA

\end{stlog}
Two ways to predict fitted values for all equations:
\begin{stlog}
predict xbB*
predict xbC xbD

\end{stlog}
Compute scores for all equations and parameters:
\begin{stlog}
predict sc*, score

\end{stlog}
Two ways to predict probability of {\tt kids}=0, using (default) first equation:
\begin{stlog}
predict prA, pr outcome(0)
predict prB, outcome(#1)

\end{stlog}
Predict {\tt kids2=4}, using second equation:
\begin{stlog}
predict prC, outcome(4) eq(kids2)

\end{stlog}
Predict all outcomes, all equations:
\begin{stlog}
predict prD*, pr

\end{stlog}
Same, but resulting variable names for the two equations start with {\tt prE} and {\tt prF} respectively:
\begin{stlog}
predict prE prF, pr

\end{stlog}
Predict all outcomes, equation 2. Generates variables {\tt prG\_\#} where {\tt \#} is outcome number (not outcome value):
\begin{stlog}
predict prG, eq(#2) pr

\end{stlog}

\doublespacing
\subsection{Tips for achieving and speeding convergence}

These techniques can help {\tt cmp} converge:
\begin{enumerate}
        \item Changing the search method using the {\tt technique()} option. The default Newton-Raphson (NR) method usually works well
            once {\tt ml} has found a concave region. The Davidon-Fletcher-Powell (DFP) algorithm {\tt (tech(dfp))} often works better before then, and the two sometimes work very well in combination, as with {\tt tech(dfp nr)}, which specifies that ml should switch between the two methods every five steps. See \rref{ml}.
        \item Switching from the default pseudo-{\tt d2} evaluator to the {\tt lf} evaluator, with the {\tt lf} option, occasionally helps.
        \item If the estimation problem requires the GHK algorithm, changing the number of draws per observation in the
            simulation sequence using the {\tt ghkdraws()} and/or {\tt ghkanti} options. Raising simulation accuracy by increasing the number of draws is sometimes necessary for convergence and can
            even speed it by improving search precision. On the other hand, especially when the number of observations is high,
            convergence can be achieved, at some loss in precision, with remarkably few draws per observations---as few as 5 when the
            sample size is 10,000 (Cappellari and Jenkins 2003). And taking more draws slows execution.
        \item adding a {\tt nrtolerance(\#)} or {\tt nonrtolerance} option to the command line if the search appears to be converging in likelihood---if the reported log likelihood is hardly changing in each iteration---and yet convergence is not declared. These are {\tt ml} options. By default, {\tt ml} declares convergence when the log
            likelihood is changing very little with successive iterations (within tolerances adjustable with the {\tt tolerance(\#)} and
            {\tt ltolerance(\#)} options) {\it and} when the calculated gradient vector is close enough to 0. In some difficult problems, such
            as ones with nearly collinear regressors, the imperfect precision of floating point numbers prevents {\tt ml} from quite
            satisfying the second criterion.  It can be loosened by using {\tt nrtolerance(\#)} to set the scaled gradient tolerance to a
            value larger than its default of $10^{-5}$, or eliminated altogether with {\tt nonrtolerance}.
        \item Exploring with {\tt cmp}'s interactive mode, described in section \ref{subsec:options}.
\end{enumerate}

\section {Conclusion}
{\tt cmp}'s estimation framework could be further developed. The requirement of full observability could be dropped: approaches developed for estimating classical simultaneous equations systems can be used to transform a system that is not fully observed into one that is. Random effects and random coefficients could be added, as could other model types; {\tt gllamm} offers these features for single-equation models (Rabe-Hesketh, Skrondal, and Pickles 2002). Equations for the latent variables could be allowed to take nonlinear forms using a syntax like that of the {\tt gmm} command. Perhaps the approach can be generalized beyond recursive systems. Still, as it stands, {\tt cmp} represents a significant new direction within the Stata universe. And beyond Stata, there appear to be few comparable tools. Faster computers and the simulated likelihood approach of the GHK algorithm are allowing practitioners to revisit models mostly developed in the late 1970s, applying direct ML estimation where it was once impractical.

\begin{thebibliography}{}

\bibitem{}Amemiya, T. 1973. Regression analysis when the dependent variable is truncated normal. {\it Econometrica} 41(6): 997--1016.

\bibitem{}Amemiya, T. 1974. Multivariate regression and simultaneous equation models when the dependent variables are truncated normal. {\it Econometrica} 42(6): 999--1012.

\bibitem{}Anderson, T.W., and H. Rubin. 1950. The asymptotic properties of estimates of the parameters of a single equation in a complete system of stochastic equations. {\it The Annals of Mathematical Statistics} 21(4): 570--82.

\bibitem{}Bolduc, D. 1999. A practical technique to estimate multinomial probit models in transportation. {\it Transportation Research, Part B} 33: 63-79.

\bibitem{}Bunch, D.S. 1991. Estimability in the multinomial probit model. {\it Transportation Research} 25B(1): 1--12.

\bibitem{}Burke, W. 2009. Fitting and interpreting Craggs tobit alternative using Stata. {\it Stata Journal} 9(4): 584--92.

\bibitem{}Cappellari, L., and S. Jenkins. 2003. Multivariate probit regression using simulated maximum likelihood. {\it Stata Journal} 3(3): 278--94.

\bibitem{}Chiburis, R., and M. Lokshin. 2007. Maximum likelihood and twostep estimation of an orderedprobit selection model. {\it Stata Journal} 7(2): 167--82.

\bibitem{}Deaton, A. 1997. {\it The Analysis of Household Surveys: A Microeconometric Approach to Development Policy}. Baltimore: Johns Hopkins University Press.

\bibitem{}Drukker, D.M., and R. Gates. 2006. Generating Halton sequences using Mata. {\it Stata Journal} 6(2): 214--28.

\bibitem{}Gates, R. 2006. A Mata Geweke-Hajivassiliou-Keane multivariate normal simulator. {\it Stata Journal} 6(2): 190--213.

\bibitem{}Genz, A. 1992. Numerical computation of multivariate normal probabilities. {\it Journal of Computational and Graphical Statistics} 1: 141-49.

\bibitem{}Geweke, J. 1989. Bayesian inference in econometric models using Monte Carlo integration. {\it Econometrica} 57: 1317-39.

\bibitem{}Gould, W., J. Pitblado, and W. Sribney. 2006. {\it Maximum Likelihood Estimation with Stata}. 3rd ed. College Station, TX: Stata Press.

\bibitem{}Greene, W.H. 1998. Gender economics courses in liberal arts colleges: further results. {\it Research in Economic Education} 29(4): 291--300.

\bibitem{}Greene, W.H. 2000. {\it Econometric Analysis}, 4th ed. Upper Saddle River, NJ: Prentice-Hall.

\bibitem{}Hajivassiliou, V., and D. McFadden. 1998. The method of simulated scores for the estimation of LDV models. {\it Econometrica} 66: 863-96.

\bibitem{}Heckman, J.J. 1976.  The common structure of statistical models of truncation, sample selection, and limited dependent variables and a simple estimator for such models. {\it Annals of Economic and Social Measurement} 5: 475--492.

\bibitem{}Heckman, J.J. 1978.  Dummy endogenous variables in a simultaneous equation system. {\it Econometrica} 46(4): 931--59.

\bibitem{}Keane, M.P. 1992. A note on identification in the multinomial probit model. {\it Journal of Business and Economics Statistics} 10(2): 193--200.

\bibitem{}Keane, M. P. 1994. A computationally practical simulation estimator for panel data. {\it Econometrica} 62: 95-116.

\bibitem{}Kelejian, H.H. 1971. Two-stage least squares and econometric systems linear in parameters but nonlinear in the endogenous variables. {\it Journal of the American Statistical Association} 66(334): 373--74.

\bibitem{}Kolenikov, S., and Angeles, G. 2004. The use of discrete data in principal component analysis with applications to socio-economic indices. CPC/MEASURE working paper WP-04-85.

\bibitem{}Lokshin, M. 2011. Impact of interventions on descrete outcomes: Maximum likelihood estimation of the binary choice
    models with binary endogenous regressors. {\it Stata Journal} 11(3): 368--85.

\bibitem{}Long, J.S., and J. Freese. 2006. {\it Regression Models for Categorical Dependent Variables Using Stata}. 2nd ed. College Station, TX: Stata Press.

\bibitem{}Maddala, G.S. 1983. {\it Limited-Dependent and Qualitative Variables in Econometrics} Cambridge, UK: Cambridge University Press.

\bibitem{}Maddala, G.S., and L. Lee 1976. Recursive models with qualitative endogenous variables. {\it Annals of Economic and Social Measurement} 5(4): 525--45.

\bibitem{}Miranda, A., and S. Rabe-Hasketh. 2006. Maximum likelihood estimation of endogenous switching
             and sample selection models for binary, count, and ordinal variables. {\it Stata Journal} 6(3): 285--308.

\bibitem{}Pagan, A. 1979. Some consequences of viewing LIML as an iterated Aitken estimator. {\it Economics Letters} 3:369--372.

\bibitem{}Pitt, M.M., and S.R. Khandker. 1998. The impact of group-based credit programs on poor households in Bangladesh: does the gender of participants matter? {\it Journal of Political Economy} 106(5): 958--96.

\bibitem{}Rabe-Hesketh, S., A. Skrondal, and A. Pickles. 2002. Reliable estimation of generalized linear mixed models using adaptive quadrature. {\it Stata Journal} 2: 1-21.

\bibitem{}Rivers, D., and Q.H. Vuong. 1988. Limited information estimators and exogeneity tests for simultaneous probit models. {\it Journal of Econometrics} 39: 347--66.

\bibitem{}Ruud, P.A. 2000. \textit{Classical Econometrics}. New York: Oxford University Press.

\bibitem{}Sajaia, Zurab. 2006. Maximum likelihood estimation of a bivariate ordered probit model: implementation and Monte Carlo simulations. Mimeo. World Bank. Washington, DC.

\bibitem{}Schmidt, P. 1981. Constrains on the parameters in simultaneous Tobit and probit models. In C.F. Manski and D.F. McFadden, eds., {\it Structural Analysis of Discrete Data and Econometric Applications}. Cambridge, MA: MIT Press.

\bibitem{}Smith, R.J., and R.W. Blundell. 1986. An exogeneity test for a simultaneous equation Tobit model with an application to labor supply. {\it Econometrica} 54(3): 679--85.

\bibitem{}Tobin, J. 1958. Estimation of relationships for limited dependent variables. {\it Econometrica} 26(1): 24--36

\bibitem{}Train, K. 2003. {\it Discrete Choice Methods with Simulation}. Cambridge: Cambridge University Press.

\bibitem{}Wilde, J. 2000. Identification of multiple equation probit models with endogenous dummy regressors. {\it Economics Letters} 69: 309--12.

\bibitem{}Wooldridge, J.M. 2002. {\it Econometric Analysis of Cross Section and Panel Data}. Cambridge, MA: MIT Press.
\end{thebibliography}

\section{About the author}
David Roodman is a senior fellow at the Center for Global Development in Washington, DC.

\appendix
\section{Appendix. Using {\tt cmp} with multinomial probit equations}
    The multinomial probit model is most complicated in theory and in implementation in {\tt cmp}. Uniquely, it can be specified in {\tt cmp} with two different command line syntaxes, roughly corresponding to the Stata commands {\tt mprobit} and
    {\tt asmprobit}. In the first syntax, the user lists a single equation, just as for other dependent variable types, and puts a 6
    (\$cmp\_mprobit) in the {\tt indicators()} list (see section \ref{subsec:syntax}). The unordered categorical dependent variable holds the choice made in each case. Like {\tt mprobit}, {\tt cmp} then treats all
    regressors as case-specific, meaning that they are determinants of the attractiveness of all alternatives. More precisely, in order to estimate, {\tt cmp} expands the specified equation into a group with one
    equation for each possible choice. All equations in this group include all regressors, except for the first, the designated base alternative which includes none (see section \ref{subsec:Multinomial probit}). This alternative
 corresponds to the lowest value of the dependent variable. The next alternative, corresponding to the
    second-lowest value, is the ``scale alternative," meaning that to normalize results, the variance of its error term is fixed. The
    value it is fixed at depends on whether the {\tt structural} option is invoked, on which see below. Unlike {\tt mprobit}, {\tt cmp} does not
    automatically make the Independence of Irrelevant Alternatives assumption. I.e., it allows a general covariance structure rather
    than assuming the errors are i.i.d. IIA can be imposed through constraints.

    A general non-IIA multinomial probit model is technically identified as long as one variable varies across alternatives. However, this model is often slippery to fit, and excluding certain regressors from certain equations, or imposing cross-equation constraints, may produce more reliable convergence (Keane 1992). Such exclusion restrictions can be impose in two ways with {\tt cmp}. The first is to use the standard {\tt constraints()} option.

    The second is to use {\tt cmp}'s other multinomial probit syntax. In this ``alternative-specific" syntax, the user lists one equation in the {\tt cmp} command line for each alternative, including the base alternative. Different equations may include different regressors. Unlike {\tt asmprobit}, {\tt cmp} does not force regressors that appear in more than one equation to have the same coefficient across alternatives, although
    again this restriction can be imposed through constraints. When using the alternative-specific syntax, the dependent variables
    listed should be a set of dummies indicating which alternatives are chosen in each case, as can be generated with {\tt xi, noomit} from the underlying polychotomous choice variable. The first equation is always treated as the base alternative, so the user can control which alternative is the base by reordering the equations. In general, regressors that appear in all other equations should be excluded from the base alternative. ({\tt cmp} automatically excludes the constant.) Variables that are specific to the base alternative, however, or to a strict subset of alternatives, can be included in the base  alternative equation.

    To specify an alternative-specific multinomial probit group, the user includes expressions in the {\tt indicators()} option that evaluate to 0 or 6 (\$cmp\_out or \$cmp\_mprobit) for each equation in the group, 0 indicating that the choice is unavailable for given observations, and encloses the whole list in an additional set of parentheses. Unlike with {\tt asmprobit}, there should be one row in
    the data set per case, not per case and alternative.

    Section \ref{subsec:Multinomial probit} explains the trade-off between two ways of parameterizing the covariance matrix of the errors. By default, {\tt cmp} interprets the {\tt lnsigma} and {\tt atanhrho} parameters as characterizing these errors after differencing with respect to the base alternative. To eliminate an excessive degree of scaling freedom, it constrains the error variance of the
    second alternative's equation (the ``scaling alternative") to 2, which it would be under the IIA, as in \eqref{differenced IIA}. If the {\tt structural} option is invoked, the parameters are interpreted as describing the error covariances before differencing. In this case, to remove the excessive degrees of freedom, {\tt cmp} constrains the base alternative
    error to have variance 1 and no correlation with the other errors; and constrains the error for the scaling alternative to
    also have variance 1.

Two examples illustrate. The first is of a multinomial probit with case-specific variables only and IIA assumed, run with both the differenced and structural parameterizations. In the structural parameterization, the covariance matrix is the identity matrix. In the differenced parameterization, it is as in \eqref{differenced IIA}:

\begin{stlog}
webuse sysdsn3, clear
mprobit insure age male nonwhite site2 site3

\end{stlog}
Replicate first with {structural parameterization: $\sigma^2$'s are 1 and $\rho$'s are 0, so lnsig's and atanhrho's are 0:
\begin{stlog}
constraint 1 [lnsig_3]_cons
constraint 2 [atanhrho_23]_cons
cmp (insure = age male nonwhite site2 site3), nolr ind(\$cmp\_mprobit) constraint(1 2) structural qui

\end{stlog}
Now with the differenced parameterization. IIA puts 2's on the diagonal and 1's off the diagonal, meaning $\sigma _{11}=\sigma _{22}=2$ and $\rho_{12}= \frac{{\sigma _{12} }}{{\sqrt {\sigma _{11} \sigma _{22} } }}=\frac{1}{2}$:
\begin{stlog}
constraint 3 [atanhrho_23]_cons = `=atanh(1/2)'
constraint 4 [lnsig_3]_cons = `=ln(sqrt(2))'
cmp (insure = age male nonwhite site2 site3), nolr ind(\$cmp\_mprobit) constraint(3 4) qui

\end{stlog}

The second example is of an alternative-specific multinomial probit with unconstrained covariance structure:

\begin{stlog}
webuse travel, clear
asmprobit choice travelcost termtime, casevars(income) case(id) alternatives(mode) struct

\end{stlog}
To replicate, we reshape the data set to have one observation per case and impose cross-equation equality on alternative-specific variables:
\begin{stlog}
drop invehiclecost traveltime partysize
reshape wide choice termtime travelcost, i(id) j(mode)
constraint 1 [air]termtime1 = [train]termtime2
constraint 2 [train]termtime2 = [bus]termtime3
constraint 3 [bus]termtime3 = [car]termtime4
constraint 4 [air]travelcost1 = [train]travelcost2
constraint 5 [train]travelcost2 = [bus]travelcost3
constraint 6 [bus]travelcost3 = [car]travelcost4
cmp (air:choice1=t*1) (train:choice2 = income t*2) (bus:choice3 = income t*3) (car:choice4 = income t*4),
        ind((6 6 6 6)) ghkanti ghkdraws(200) ghktype(hammersley) constraints(1/6) nodrop structural
        tech(dfp nr) nrtol(1e-4)

\end{stlog}

\pagebreak
\appendix
\section{Web appendix: Likelihood and scores for fully observed mixed-process SUR}
\subsection{Practical computation of the likelihood}
Recasting \eqref{Cartesian T}, \eqref{SUR likelihood}, and \eqref{general h inv}, our task is to express the observation-level likelihood
\begin{align}
& L_i\left({\bf B},{\bm \Sigma}, {\bf c};{\bf y}_i|{\bf x}_i\right)= \frac
{\displaystyle{\int\limits_C {\phi \left( {\bm \varepsilon}; {\bm \Sigma} \right){\bm {d { \varepsilon}}}}}}
{\displaystyle{\int\limits_T {\phi \left( {\bm \varepsilon}; {\bm \Sigma} \right){\bm {d { \varepsilon}}}}}} \label{recast SUR likelihood}
\\
& C = \left[ \underline c_1 , \bar c_1 \right] \times \hdots \times \left[ \underline c_J , \bar c_J \right] \notag \\
& T = \left[ \underline \tau_1 , \bar \tau_1 \right] \times \hdots \times \left[ \underline \tau_J , \bar \tau_J \right] \notag
\end{align}
in a computationally tractable form. In any given dimension, each region of integration will be finite or infinite or---in the numerator, for uncensored observations---infinitesimal.

Just as in Example 2, if we order equations to put the uncensored observations before the censored ones and partition ${ {\bm \varepsilon}}$ and ${\bm { \Sigma}}$ accordingly, the numerator is
\begin{align}
\phi \left({ {\bm \varepsilon}}_1;{\bm { \Sigma}}_{11}\right)\int\limits_C{\phi\left( { {\bm \varepsilon}}_2 - {\bm \mu}_{2 | 1}; {\bm \Sigma}_{2 | 1}\right) d { {\bm \varepsilon}}_2}.
\label{SUR likelihood numerator}
\end{align}
Let ${\bf T}$ be the Cholesky factor of ${\bm { \Sigma}}_{11}$. Then ${\bm { \Sigma}}_{11}^{-1}={{\bf T}^{-1}}'{\bf T}^{-1}$, and the first factor in \eqref{SUR likelihood numerator}, a multivariate normal density, can be rewritten in logs as
\begin{align*}
\ln  \phi \left({ {\bm \varepsilon}}_1;{\bm { \Sigma}}_{11}\right) &=
 - \frac{1}{2}\left( {\ln \left| {2\pi \bm \Sigma_{11} } \right| + {\bm \varepsilon }_1 '  \bm \Sigma_{11}^{ - 1} {\bm \varepsilon }_1 } \right) =  - \frac{1}{2}\left( {\ln \left| {2\pi {\bf TT}'} \right| + {\bm \varepsilon }_1 '  {{\bf T}^{ - 1}} '  {\bf T}^{ - 1} {\bm \varepsilon }_1 } \right) \\
 & =  - \frac{1}{2}\left( {\ln \left| {2\pi } \right| + \left({\bf T}^{ - 1} {\bm \varepsilon }_1\right)'  {\bf T}^{ - 1} {\bm \varepsilon }_1 } \right) - \ln \left| {\bf T} \right| = \ln  \phi \left( {{\bf T}^{ - 1} {\bm \varepsilon }_1 ;{\bf I}} \right) - \ln \left| {\bf T} \right|
\end{align*}
where $\phi \left( \cdot ;{\bf I} \right)$ is a multivariate standard normal p.d.f. The $j^{th}$ entry of ${\bf T}^{ - 1} {\bm \varepsilon }_1$ is ${\bf T}^{ - 1}_j {\bm \varepsilon }_1$, where ${\bf T}^{ - 1}_j$ is the $j^{th}$ row of ${\bf T}^{ - 1}$. So the above is
\begin{align*}
\ln  \phi \left({ {\bm \varepsilon}}_1;{\bm { \Sigma}}_{11}\right) = \left[\sum\limits_j \ln  \phi \left({\bf T}^{ - 1}_j {\bm \varepsilon }_1 ;1  \right) \right] - \ln \left| {\bf T} \right|,
\end{align*}
which can be calculated with standard software functions.

The second term in \eqref{SUR likelihood numerator}, a cumulative probability, is fairly straightforward to compute if it has dimension 1 or 2. If it has dimension 1, it is
\begin{align*}
\int\limits_C{\phi\left( { {\bm \varepsilon}}_2 - {\bm \mu}_{2 | 1}; {\bm \Sigma}_{2 | 1}\right) d { {\bm \varepsilon}}_2} = \Phi\left( \frac { \bar c^J - {\bm \mu}_{2 | 1} }{\sqrt{ {\bm \Sigma}_{2 | 1}}}\right) - \Phi\left( \frac { \underline c^J - {\bm \mu}_{2 | 1} }{ \sqrt{{\bm \Sigma}_{2 | 1}}}\right).
\end{align*}
If the dimension is 2, then let ${\bf V}$ be the $2 \times 2$ diagonal matrix that normalizes against the assumed variances, so that ${\bf R}_{2 | 1} = {\bf V}{\bm \Sigma}_{2 | 1}{\bf V}'$ is a correlation matrix. The term equals
\begin{align*}
\int\limits_C{\phi\left( {\bf V}\left({ {\bm \varepsilon}}_2 - {\bm \mu}_{2 | 1}\right); {\bf V}{\bm \Sigma}_{2 | 1}{\bf V}'\right) d { {\bm \varepsilon}}_2} =
\int\limits_C{\phi\left( {\bf V}\left({ {\bm \varepsilon}}_2 - {\bm \mu}_{2 | 1}\right); {\bf R}_{2 | 1}\right) d { {\bm \varepsilon}}_2}.
\end{align*}
This can be computed with 1, 2, or 4 calls to Mata's {\tt binormal()}, as described in section \ref{subsec:ghk2}, depending on how many of the bounds of $C$ are finite. ({\tt binormal()} requires that the variables in the two dimensions have unit variance and accepts a single correlation parameter to characterize their covariance.)

If the cumulative probability has dimension 3 or higher, it is estimated with the GHK algorithm, as described in Web Appendix B.

The cumulative probability over the truncation region in the denominator of \eqref{recast SUR likelihood} is computed in the same manner.

\subsection{Scores}
Since the log likelihood is
\begin{align*}
 \ln  L_i\left({\bf B},{\bm \Sigma}, {\bf c};{\bf y}_i|{\bf x}_i\right)= \ln  \phi \left({ {\bm \varepsilon}}_1;{\bm { \Sigma}}_{11}\right) + \ln  \int\limits_C{\phi\left( { {\bm \varepsilon}}_2 - {\bm \mu}_{2 | 1}; {\bm \Sigma}_{2 | 1}\right) d { {\bm \varepsilon}}_2} -
\ln  \int\limits_T {\phi \left( {\bm \varepsilon}; {\bm \Sigma} \right){\bm {d { \varepsilon}}}},
\end{align*}
the challenge in computing scores lies mostly in computing derivatives of multivariate normal p.d.f.'s and c.d.f.'s, as well as of ${\bm \mu}_{2 | 1}$ and ${\bm \Sigma}_{2 | 1}$.

A final step is to translate scores with respect to ${\bm \varepsilon}$ into ones with respect to ${\bf B}$, and to move from derivatives with respect to ${\tilde {\bm \Sigma}}$ to ones with respect to ${\bm \Sigma}$, a distinction relevant for multinomial probits. Since that last step involves only linear transformations, it is straightforward and not elaborated on here.

\subsubsection{Scores of the multivariate normal p.d.f.}
\label{subsubsec:pdf scores}
For a $d$-dimensional normal p.d.f.,
\begin{align*}
\frac{{\partial \ln \phi \left( {{\bm \varepsilon },\bm \Sigma} \right)}}{{\partial {\bm \varepsilon }}} = -\frac{1}{2}\frac{\partial }{{\partial {\bm \varepsilon }}}\left( {\ln \left| 2\pi \bm \Sigma \right| + \frac{1}{2}\bm \varepsilon ' \bm \Sigma^{ - 1} {\bm \varepsilon }} \right) =  - \frac{1}{2}\left( {2{\bm \varepsilon '\Sigma }^{ - 1} } \right) =  - {\bm \varepsilon '\Sigma }^{ - 1},
\end{align*}
the second step using the matrix identity $\partial\left({\bf b'Ab}\right)/\partial{\bf b}=2{\bf b'A}$.

To compute the derivative with respect to a lower-triangular element $j,k$ of ${\bm \Sigma}$, we start by viewing all elements of ${\bm \Sigma}$ as independent, ignoring the necessity of symmetry. Proceeding as above,
\begin{align}
\frac{{\partial \ln \phi \left( {{\bm \varepsilon },\bm \Sigma} \right)}}{{\partial \bm \Sigma_{jk} }} =  - \frac{1}{2}\left( {\frac{{\partial \ln \left| \bm \Sigma \right|}}{{\partial \bm \Sigma_{jk} }} + {\bm \varepsilon '}\frac{{\partial \bm \Sigma^{ - 1} }}{{\partial \bm \Sigma_{jk} }}{\bm \varepsilon }} \right).
\label{score pdf Sigma}
\end{align}
A formula for the derivative of the determinant turns the first term into
\begin{align*}
\frac{{\partial \ln \left| \bm \Sigma \right|}}{{\partial \bm \Sigma_{jk} }} = \frac{1}{{\left| \bm \Sigma \right|}}\frac{{\partial \left| \bm \Sigma \right|}}{{\partial \bm \Sigma_{jk} }} = \frac{1}{{\left| \bm \Sigma \right|}}\left| \bm \Sigma \right|\left( {\bm \Sigma^{ - 1} } \right)_{jk}=\bm\Sigma^{-1}_{jk},
\end{align*}
meaning element $j,k$ of $\bm \Sigma^{ - 1}$. Using a formula for the derivative of the matrix inverse, the second term of \eqref{score pdf Sigma} contains
\begin{align*}
\frac{{\partial \bm \Sigma^{ - 1} }}{{\partial \bm \Sigma_{jk} }} =  - \bm \Sigma^{ - 1} \frac{{\partial \bm \Sigma}}{{\partial \bm \Sigma_{jk} }}\bm \Sigma^{ - 1}  =  - \bm \Sigma^{ - 1} {\bf S}_{jk} \bm \Sigma^{ - 1} =  - {\bm \Sigma_j^{ - 1}} '  \bm \Sigma_k^{ - 1}
\end{align*}
where ${\bf S}_{jk}$ is all 0's except for a 1 in position $j,k$.

Putting all this together,
\begin{align*}
\frac{{\partial \ln \phi \left( {{\bm \varepsilon },\bm \Sigma} \right)}}{{\partial \bm \Sigma_{jk} }} =  - \frac{1}{2}\left( { \bm \Sigma^{ - 1}  _{jk}  - {\bm \varepsilon '\bm \Sigma_j^{ - 1}} '  \bm \Sigma_k^{ - 1} {\bm \varepsilon }} \right) =   \frac{1}{2}\left( {  \left( {\bm \Sigma_j}^{ - 1} {\bm \varepsilon } \right)\left( {\bm \Sigma_k^{ - 1} {\bm \varepsilon }} \right) - \bm \Sigma^{ - 1}  _{jk} } \right)=\frac{1}{2}\left({\bm \Sigma}^{ - 1} {\bm \varepsilon }{\bm \varepsilon }'{\bm \Sigma}^{ - 1}- {\bm \Sigma^{ - 1}}\right)_{jk}.
\end{align*}
This is symmetric in $j,k$. So to account for the required symmetry of $\bm \Sigma$---$\bm \Sigma_{kj}$ moves in tandem with $\bm \Sigma_{jk}$---we double this quantity for off-diagonal entries of ${\bm \Sigma}$.

\subsubsection{Scores of the multivariate normal c.d.f.}
For a 1-dimensional distribution, the derivatives of the c.d.f. are
\begin{align*}
\frac{{\partial \Phi \left( {\varepsilon ,\Sigma } \right)}}{{\partial \varepsilon }} &= {\phi \left( {\varepsilon ,\Sigma } \right)} \\
\frac{{\partial \Phi \left( {\varepsilon ,\Sigma } \right)}}{{\partial \Sigma }} &= \frac{{\partial \Phi \left( {\frac{\varepsilon }{{\sqrt \Sigma  }},1} \right)}}{{\partial \Sigma }} = \phi \left( {\frac{\varepsilon }{{\sqrt \Sigma  }},1} \right) \cdot \frac{\partial }{{\partial \Sigma }}\left( {\frac{\varepsilon }{{\sqrt \Sigma  }}} \right) = \sqrt \Sigma  \phi \left( {\varepsilon ,\Sigma } \right) \cdot \left( { - \frac{1}{2}} \right)\frac{\varepsilon }{{\Sigma \sqrt \Sigma  }} =  - \frac{\varepsilon }{{2\Sigma }}\phi \left( {\varepsilon ,\Sigma } \right).
\end{align*}

For a 2-dimensional distribution,
\begin{align}
 \frac{{\partial \Phi \left( {{\bm \varepsilon },\bm \Sigma} \right)}}{{\partial \varepsilon _1 }} &= \frac{\partial }{{\partial \varepsilon _1 }}\int_{ - \infty }^{\varepsilon_1 } {\int_{ - \infty }^{\varepsilon_2 } {\phi \left( {{\bf x},\bm \Sigma } \right)dx_2 dx_1 } }  = \frac{\partial }{{\partial \varepsilon _1 }}\int_{ - \infty }^{\varepsilon _1 } {\phi \left( {x_1 ,\Sigma_{11} } \right)\int_{ - \infty }^{\varepsilon _2 } {\phi \left( {x_{2 | 1} ,\Sigma_{2 | 1} } \right)dx_2 dx_1 } }  \notag \\ &=
 \frac{\partial }{{\partial \varepsilon _1 }}\int_{ - \infty }^{\varepsilon _1 } {\phi \left( {x_1 ,\Sigma_{11} } \right)\Phi \left( {\varepsilon_{2 | 1} ,\Sigma_{2 | 1} } \right)dx_1 }  = \phi \left( {\varepsilon _1 ,\Sigma_{11} } \right)\Phi \left( {\varepsilon _{2 | 1} ,\Sigma_{2 | 1} } \right),
\label{2-dim score epsilon_1}
\end{align}
and likewise, symmetrically, for ${\bm \varepsilon_2}$. (Here, the definition of $\varepsilon_{2|1}$ slips from being relative to $x_1$ to being relative to $\varepsilon_1$.)

As for the derivatives of a 2-dimensional c.d.f with respect to elements of ${\bm \Sigma}$, we start with ${\Sigma}_{12}$. Using the rules just devised for the 1-dimensional case, the derivative is
\begin{align}
 \frac{\partial \Phi \left( \bm \varepsilon ,\Sigma \right)}{\partial \Sigma_{12} } &= \frac{\partial }{\partial \Sigma_{12} }\int_{ - \infty }^{\varepsilon _1 } {\phi \left(x_1 ,\Sigma_{11} \right) \Phi \left( \varepsilon _{2 | 1} ,\Sigma_{2 | 1}  \right) dx_1}  = \int_{ - \infty }^{\varepsilon _1 } {\phi \left(x_1 ,\Sigma_{11} \right) \frac{\partial \Phi \left( \varepsilon _{2 | 1} ,\Sigma_{2 | 1}  \right)}{\partial \Sigma_{12} }  dx_1}  \notag \\
  &= \int_{ - \infty }^{\varepsilon _1 } {\phi \left(x_1 ,\Sigma_{11} \right) \left[\frac{\partial \Phi \left( \varepsilon _{2 | 1} ,\Sigma_{2 | 1}  \right)}{\partial \varepsilon _{2 | 1} }\frac{\partial \varepsilon _{2 | 1} }{\partial \Sigma_{12} } + \frac{\partial \Phi \left( \varepsilon _{2 | 1} ,\Sigma_{2 | 1}  \right)}{\partial \Sigma_{2 | 1} }\frac{\partial \Sigma_{2 | 1} }{\partial \Sigma_{12} } \right] dx_1 }  \notag \\
  &= \int_{ - \infty }^{\varepsilon _1 } {\phi \left(x_1 ,\Sigma_{11} \right) \left[ \phi \left( \varepsilon _{2 | 1} ,\Sigma_{2 | 1} \right)\frac{\partial \varepsilon _{2 | 1} }{\partial \Sigma_{12} } - \phi \left( \varepsilon _{2 | 1} ,\Sigma_{2 | 1} \right)\frac{\varepsilon _{2 | 1}}{2\Sigma _{2 | 1} }\frac{\partial \Sigma_{2 | 1} }{\partial \Sigma_{12} } \right] dx_1 }  \notag \\
  &= \int_{ - \infty }^{\varepsilon_1 } {\phi \left( \left(x_1,\varepsilon _2 \right)',\Sigma \right)\left[ \frac{\partial \varepsilon _{2 | 1} }{\partial \Sigma_{12} } - \frac{\varepsilon _{2 | 1} }{2\Sigma_{2 | 1} }\frac{\partial \Sigma_{2 | 1} }{\partial \Sigma_{12} } \right]dx_1 }.
\label{2-dim score Sigma_12}
\end{align}
Here,
\begin{align*}
 \frac{{\partial \varepsilon _{2 | 1} }}{{\partial \Sigma_{12} }} &= \frac{\partial }{\partial \Sigma_{12} }\left( {\varepsilon _2  - \frac{{\Sigma_{12} }}{{\Sigma_{11} }}x_1 } \right) =  - \frac{{x_1 }}{{\Sigma_{11} }} \\
 \frac{\partial \Sigma _{2 | 1} }{\partial \Sigma_{12} } &= \frac{\partial }{{\partial \Sigma_{12} }}\left( {\Sigma_{22}  - \frac{{\bm \Sigma_{21} \Sigma_{12} }}{{\Sigma_{11} }}} \right) =  - \frac{{2\Sigma_{12} }}{{\Sigma_{11} }}
\end{align*}
(keeping in mind that $\Sigma_{12} = \Sigma_{12}$), so the bracketed expression in \eqref{2-dim score Sigma_12} works out to
\begin{align*}
\frac{{\partial \varepsilon _{2 | 1} }}{{\partial \Sigma_{12} }} - \frac{{\varepsilon _{2 | 1} }}{{2\Sigma_{2 | 1} }}\frac{{\partial \Sigma_{2 | 1} }}{{\partial \Sigma_{12} }} =
- \frac{{x_1 }}{{\Sigma_{11} }} - \frac{1}{2} \frac{ {\varepsilon _2  - \displaystyle{\frac{{\Sigma_{12} }}{{\Sigma_{11} }}}x_1 }}{{\Sigma_{22}  - \displaystyle{\frac{{\bm \Sigma_{21} \Sigma_{12} }}{{\Sigma_{11} }}}}} \left(- \frac{{2\Sigma_{12} }}{{\Sigma_{11} }}\right) =
 - \frac{{x_1  - \displaystyle{\frac{{\Sigma_{12} }}{{\Sigma_{22} }}}\varepsilon _2 }}{{\Sigma_{11}  - \displaystyle{\frac{{\bm \Sigma_{21} \Sigma_{12} }}{{\Sigma_{22} }}}}} =  - \frac{{x _{1 | 2} }}{{\bm \Sigma_{1 | 2} }}.
\end{align*}
Substituting into \eqref{2-dim score Sigma_12},
\begin{align}
\frac{\partial \Phi \left( {\bm \varepsilon },\bm \Sigma \right)}{{\partial \Sigma_{12} }} &= \int_{ - \infty }^{\varepsilon _1 } {\phi \left( {\left( {x_1 ,\varepsilon _2 } \right)'  ,\bm \Sigma} \right)\left( { - \frac{x _{1 | 2}}{\Sigma_{1 | 2} }} \right)dx_1 }  = \phi \left( {\varepsilon _2 ,\Sigma_{22} } \right)\int_{ - \infty }^{\varepsilon _1 } {\phi \left( {x_{1 | 2} ,\bm \Sigma_{1 | 2} } \right)\left( { - \frac{{x_{1 | 2} }}{{\bm \Sigma_{1 | 2} }}} \right)dx_1 }  \notag \\
&= \phi \left( {\varepsilon _2 ,\Sigma_{22} } \right) \cdot \left. {\phi \left( {x_{1 | 2} ,\Sigma_{1 | 2} } \right)} \right]_{ - \infty }^{\varepsilon _1 }
= \phi \left( {\varepsilon _2 ,\Sigma_{22} } \right) {\phi \left( {\varepsilon_{1 | 2} ,\Sigma_{1 | 2} } \right)}
 = \phi \left( {{\bm \varepsilon },\bm \Sigma} \right)
\label{2-dim score Sigma_12 final}
\end{align}
(rather remarkably).

To compute the derivative of the 2-dimensional normal c.d.f with respect to $\Sigma_{11}$, let ${\bm \nu}=\left(\displaystyle{\frac{\varepsilon_1}{\sqrt {\Sigma_{11}}}},\varepsilon_2\right)'$ and
\begin{align*}
{\bm \Omega } = {\mathop{\rm Var}\nolimits} \left[ {\bm \nu } \right] = \left[ {\begin{array}{*{20}c}
   1 & {\displaystyle{\frac{{\Sigma _{12} }}{{\sqrt {\Sigma _{11} } }}}}  \\
   {\displaystyle{\frac{{\Sigma _{21} }}{{\sqrt {\Sigma _{11} } }}}} & {\Sigma _{22} }
\end{array}} \right]
\end{align*}
so that $\Phi \left( {{\bm \varepsilon },\bm \Sigma} \right) = \Phi \left( {{\bm \nu },{\bm \Omega }} \right)$. Then
\begin{align*}
\frac{{\partial \Phi \left( {{\bm \varepsilon },\bm \Sigma} \right)}}{{\partial \Sigma _{11} }} &= \frac{{\partial \Phi \left( {{\bm \nu },{\bm \Omega }} \right)}}{{\partial \Sigma _{11} }} = \frac{{\partial \Phi \left( {{\bm \nu },{\bm \Omega }} \right)}}{{\partial \nu _1 }}\frac{{\partial \nu _1 }}{{\partial \Sigma _{11} }} + \frac{{\partial \Phi \left( {{\bm \nu },{\bm \Omega }} \right)}}{{\partial \Omega _{12} }}\frac{{\partial \Omega _{12} }}{{\partial \Sigma _{11} }} \\
&= \phi \left( {\nu _1 ,\Omega _{11} } \right)\Phi \left( {\nu _{2 | 1} ,\Omega _{2 | 1} } \right)\left( { - \frac{{\varepsilon _1 }}{{2\Sigma _{11} \sqrt {\Sigma _{11} } }}} \right) + \phi \left( {{\bm \nu },{\bm \Omega }} \right)\left( { - \frac{{\Sigma _{12} }}{{2\Sigma _{11} \sqrt {\Sigma _{11} } }}} \right),
\end{align*}
the last step expanding with \eqref{2-dim score epsilon_1} and \eqref{2-dim score Sigma_12 final}. Since $\phi \left( {\nu _1 ,\Omega _{11} } \right)=
\sqrt {\Sigma _{11} } \phi \left( {\varepsilon _1 ,\Sigma _{11} } \right)$ and $\phi \left( {{\bm \nu },{\bm \Omega }} \right)=
\sqrt {\Sigma _{11} } \phi \left( {{\bm \varepsilon },\bm \Sigma} \right)$,
\begin{align*}
 \frac{{\partial \Phi \left( {{\bm \varepsilon },\bm \Sigma} \right)}}{{\partial \Sigma _{11} }} &= \sqrt {\Sigma _{11} } \phi \left( {\varepsilon _1 ,\Sigma _{11} } \right)\Phi \left( {\varepsilon _{2 | 1} ,\Sigma _{2 | 1} } \right)\left( { - \frac{{\varepsilon _1 }}{{2\Sigma _{11} \sqrt {\Sigma _{11} } }}} \right) + \sqrt {\Sigma _{11} } \phi \left( {{\bm \varepsilon },\bm \Sigma} \right)\left( { - \frac{{\Sigma _{12} }}{{2\Sigma _{11} \sqrt {\Sigma _{11} } }}} \right) \\
  &=  - \frac{1}{{2\Sigma _{11} }}\left( {\varepsilon _1 \phi \left( {\varepsilon _1 ,\Sigma _{11} } \right)\Phi \left( {\varepsilon _{2 | 1} ,\Sigma _{2 | 1} } \right) + \Sigma _{12} \phi \left( {{\bm \varepsilon },\bm \Sigma} \right)} \right) \\
  &=  - \frac{{\phi \left( {\varepsilon _1 ,\Sigma _{11} } \right)}}{{2\Sigma _{11} }}\left( {\varepsilon _1 \Phi \left( {\varepsilon _{2 | 1} ,\Sigma _{2 | 1} } \right) + \Sigma _{12} \phi \left( {\varepsilon _{2 | 1} ,\Sigma _{2 | 1} } \right)} \right).
\end{align*}
The formula for $\displaystyle{\frac{{\partial \Phi \left( {{\bm \varepsilon },\bm \Sigma} \right)}}{{\partial \Sigma _{22} }}}$ is of course analogous.

Since cumulative normal distributions above dimension 2 are simulated with the GHK algorithm, the derivatives of that algorithm need to be computed according to the exact formulas for the simulation, rather than with ones like those above. See Web Appendix B.

\subsubsection{Derivatives of $\bm \varepsilon_{2| 1}$ and $\bm \Sigma_{2| 1}$}
To state the derivatives of $\bm \varepsilon_{2| 1}=\bm \varepsilon_2 - {\bm \Sigma}_{21}{\bm \Sigma}_{11}^{-1}{\bf \varepsilon}_1$ and ${\bm \Sigma}_{2 | 1}= {\bm \Sigma}_{22} -{\bm \Sigma}_{21}{\bm \Sigma}_{11}^{-1}{\bm \Sigma}_{12}$, let $\bm \beta = \bm \Sigma_{21} \bm \Sigma_{11}^{ - 1}$ and ${\bf P} = \left[ {\left. { - \bm \beta} \right|{\bf I}} \right]$. So ${\bm \varepsilon }_{2 | 1}  = {\bf P}{\bm \varepsilon }$ and $\bm \Sigma_{2| 1}=\operatorname{Var}\left[\bm \varepsilon_{2| 1}\right]={\bf P}\bm \Sigma{\bf P}'$. Then
\begin{align*}
\frac{{\partial {\bm \varepsilon }_{2 | 1} }}{{\partial {\bm \varepsilon }}} = {\bf P}
\end{align*}
and
\begin{align*}
&\frac{{\partial {\bf \Sigma }_{2|1,ij} }}{{\partial {\bf \Sigma }_{kl} }} = \frac{{\partial \left( {{\bf P\Sigma P'}} \right)_{ij} }}{{\partial {\bf \Sigma }_{kl} }} = \frac{{\partial \left( {{\bf P}_i {\bf \Sigma P}_j' } \right)}}{{\partial {\bf \Sigma }_{kl} }} = {\bf P}_i \frac{{\partial {\bf \Sigma }_j }}{{\partial {\bf \Sigma }_{kl} }}{\bf P_j'} = {\bf P}_i {\bf S}_{kl} {\bf P}_j'  = {\bf P}_{ik} {\bf P}_{jl} \\
\Rightarrow &\frac{{\partial \operatorname{vec} \left(\bm \Sigma_{2 | 1} \right)}}{{\partial {\mathop{\rm vec}\nolimits} \left( \bm \Sigma \right)}} = {\bf P} \otimes {\bf P}.
\end{align*}

\section{Web appendix: Formulas for the GHK estimate and scores thereof when integration regions are bounded below and above}
\label{appendix:GHK}
This appendix exhibits the formulas for the GHK estimator when lower as well upper bounds of integration are provided. It also shows how scores are computed. It borrows the notation of Gates (2006) and provides almost no motivation.

Our task is to integrate the ${\bf 0}$-centered $d$-dimensional normal distribution with covariance ${\bm \Sigma}$ over the Cartesian region defined by lower and upper bounds $\underline{\bf x}=\left(\underline{x}_1, \hdots, \underline{x}_d\right)'$, $\bar{\bf x}=\left(\bar{x}_1, \hdots, \bar{x}_d\right)'$, which can have infinite entries. Let ${\bf T}=\left[t_{ij}\right]_{i,j=1\hdots d}$ be the Cholesky factor of ${\bm \Sigma}$: ${\bm \Sigma}={\bf TT}'$. Let $u_1{\hdots}u_d$ be a sequence of draws distributed across the unit interval $\left[0,1\right)$. Let $\Phi\left( \cdot \right)$ be the standard cumulative normal distribution function. Then the simulated probability, $p$, for this sequence is estimated by the algorithm:

$\underline{b}_1 := \underline{x}_1/t_{11}$, $\bar{b}_1 := \bar{x}_1/t_{11}$

$a_1 := \Phi\left(\bar{b}_1\right) - \Phi\left(\underline{b}_1\right)$

For $i:=2, \hdots, d$,

\qquad\qquad$z_{i-1}:=\Phi^{-1}\left(a_{i-1}\right)$

\qquad\qquad$\underline{b}_i  := {{\left( {\underline{x}_i  - \sum\limits_{j = 1}^{i - 1} {t_{ij} z_j } } \right)} \mathord{\left/
 {\vphantom {{\left( {x_i^l  - \sum\limits_{j = 1}^{i - 1} {t_{ij} z_j } } \right)} {t_{ii} }}} \right.
 \kern-\nulldelimiterspace} {t_{ii} }}$

\qquad\qquad$\bar{b}_i  := {{\left( {\bar{x}_i  - \sum\limits_{j = 1}^{i - 1} {t_{ij} z_j } } \right)} \mathord{\left/
 {\vphantom {{\left( {\bar{x}_i  - \sum\limits_{j = 1}^{i - 1} {t_{ij} z_j } } \right)} {t_{ii} }}} \right.
 \kern-\nulldelimiterspace} {t_{ii} }}$

\qquad\qquad$a_i := \left(1-u_i\right) \Phi\left(\underline{b}_i\right) + u_i \Phi\left(\bar{b}_i\right)$.

$p := \prod\limits_{i=1}^d {\left(\Phi\left(\bar{b}_i\right) - \Phi\left(\underline{b}_i\right)\right)}$

\noindent where $:=$ indicates assignment.

The algorithm is repeated for many sequences of draws and then $p$ is averaged over all these sequences for the final simulated probability.

To discuss the derivatives of the probability with respect to the parameters $\underline{\bf x}$, $\bar{\bf x}$, and $\operatorname{vech}\left({\bf T}\right)$, concatenate them into a single parameter vector $\delta$; and interpret subscripting with ``$\left(i\right)$'' as taking the first $i$ entries of a vector. Following Bolduc (1999), we state the derivatives in a recursive manner, through repeated use of the chain rule. Let $\delta_m$ be a parameter. In general,
\begin{align*}
\frac{{\partial p}}{{\partial \delta_m }} = p \frac{{\partial \ln p}}{{\partial \delta_m }} = p\sum\limits_{j = 1}^d {\frac{{\partial \ln \left( {\Phi \left( {\bar{b}_j } \right) - \Phi \left( {\underline{b}_j } \right)} \right)}}{{\partial \delta_m }}}  = p\sum\limits_{j = 1}^d {\frac{{\phi \left( {\bar{b}_j } \right)\displaystyle\frac{{\partial \bar{b}_j }}{{\partial \delta_m }} - \phi \left( {\underline{b}_j } \right)\displaystyle\frac{{\partial \underline{b}_j }}{{\partial \delta_m }}}}{{\Phi \left( {\bar{b}_j } \right) - \Phi \left( {\underline{b}_j } \right)}}}
\end{align*}
where $\phi\left(\cdot\right)$ is the standard normal distribution. So our task is to compute $\displaystyle\frac{{\partial \underline{b}_j }}{{\partial \delta_m}}$ and $\displaystyle\frac{{\partial \bar{b}_j }}{{\partial \delta_m }}$ in the above, which we do by differentiating the formulas in the algorithm:

\noindent {\it Case $\delta_m$ is $\underline{x}_i$ for some $i$:}
\begin{align*}
\frac{{\partial \underline{b}_j }}{{\partial \underline{x}_i }} = \left\{ {\begin{array}{*{20}c}
   \displaystyle{\frac{1}{{t_{jj} }}} \hfill & {{\rm if~}i = j} \hfill  \\
   \displaystyle{ - \frac{1}{{t_{jj} }}\sum\limits_{k = 1}^{j - 1} {t_{jk} \frac{{\partial z_k }}{{\partial \underline{x}_i }}} } \hfill & {{\rm if~}i < j} \hfill  \\
   0 \hfill & {{\rm otherwise}} \hfill  \\
\end{array}} \right.
\text{ and~}
\frac{{\partial \bar{b}_j }}{{\partial \underline{x}_i }} = \left\{ {\begin{array}{*{20}c}
   0 \hfill & {{\rm if~}i = j} \hfill  \\
   \displaystyle{ - \frac{1}{{t_{jj} }}\sum\limits_{k = 1}^{j - 1} {t_{jk} \frac{{\partial z_k }}{{\partial \underline{x}_i }}} } \hfill & {{\rm if~}i < j} \hfill  \\
   0 \hfill & {{\rm otherwise}} \hfill
\end{array}} \right.
\end{align*}
(These two are identical except when $i = j$.)

\noindent {\it Case $\delta_m$ is $\bar{x}_i$ for some $i$:}
\begin{align*}
\frac{{\partial \underline{b}_j }}{{\partial \bar{x}_i }} = \left\{ {\begin{array}{*{20}c}
   0 \hfill & {{\rm if~}i = j} \hfill  \\
   \displaystyle{ - \frac{1}{{t_{jj} }}\sum\limits_{k = 1}^{j - 1} {t_{jk} \frac{{\partial z_k }}{{\partial \bar{x}_i }}} } \hfill & {{\rm if~}i < j} \hfill  \\
   0 \hfill & {{\rm otherwise}} \hfill  \\
\end{array}} \right.
\text{ and~}
\frac{{\partial \bar{b}_j }}{{\partial \bar{x}_i }} = \left\{ {\begin{array}{*{20}c}
   \displaystyle{\frac{1}{{t_{jj} }}} \hfill & {{\rm if~}i = j} \hfill  \\
   \displaystyle{ - \frac{1}{{t_{jj} }}\sum\limits_{k = 1}^{j - 1} {t_{jk} \frac{{\partial z_k }}{\partial \bar{x}_i }} } \hfill & {{\rm if~}i < j} \hfill  \\
   0 \hfill & {{\rm otherwise}} \hfill
\end{array}} \right.
\end{align*}
(Again, these two are identical unless $i = j$.)

\noindent {\it Case $\delta_m$ is $t_{ik}$ for some $i,k, i \ge k$:}
\begin{align*}
\frac{{\partial \underline{b}_j }}{{\partial t_{ik} }} = \left\{ {\begin{array}{*{20}c}
   \displaystyle{ - \frac{{\underline{b}_j }}{{t_{jj} }}} \hfill & {{\rm if~}j = i = k} \hfill  \\
   \displaystyle{ - \frac{{z_k }}{{t_{jj} }}} \hfill & {{\rm if~}j = i > k} \hfill  \\
   \displaystyle{ - \frac{1}{{t_{jj} }}\sum\limits_{h = 1}^{j - 1} {t_{jh} \frac{{\partial z_h }}{{\partial t_{ik} }}} } \hfill & {{\rm if~}j > i \ge k} \hfill  \\
\end{array}} \right.
\text{ and~}
\frac{{\partial \bar{b}_j }}{{\partial t_{ik} }} = \left\{ {\begin{array}{*{20}c}
   \displaystyle{ - \frac{{\bar{b}_j }}{{t_{jj} }}} \hfill & {{\rm if~}j = i = k} \hfill  \\
   \displaystyle{ - \frac{{z_k }}{{t_{jj} }}} \hfill & {{\rm if~}j = i > k} \hfill  \\
   \displaystyle{ - \frac{1}{{t_{jj} }}\sum\limits_{h = 1}^{j - 1} {t_{jh} \frac{{\partial z_h }}{{\partial t_{ik} }}} } \hfill & {{\rm if~}j > i \ge k} \hfill  \\
\end{array}} \right.
\end{align*}
(These two are the same except when $j = i = k$.)

All three cases contain derivatives of $z_k$, which we expand recursively with
\begin{align*}
\frac{{\partial z_k }}{{\partial \delta_m }} = \frac{{\partial \Phi ^{ - 1} \left( {a_k } \right)}}{{\partial \delta_m }} = \frac{1}{{\phi \left( {\Phi ^{ - 1} \left( {a_k } \right)} \right)}}\frac{{\partial a_k }}{{\partial \delta_m }} = \frac{1}{{\phi \left( {z_k } \right)}}\left[ {u_k  \cdot \phi \left( {\bar{b}_k } \right)\frac{{\partial \bar{b}_k }}{{\partial \delta_m }} + \left( {1 - u_k } \right) \cdot \phi \left( {\underline{b}_k } \right)\frac{{\partial \underline{b}_k }}{{\partial \delta_m }}} \right].
\end{align*}
We can also write this as $\displaystyle{\frac{{\partial z_k }}{{\partial \delta_m }} = \frac{{\partial z_k }}{{\partial \bar{b}_k }}\frac{{\partial \bar{b}_k }}{{\partial \delta_m }} + \frac{{\partial z_k }}{{\partial \underline{b}_k }}\frac{{\partial \underline{b}_k }}{{\partial \delta_m }}}$ where $\displaystyle{\frac{{\partial z_k }}{{\partial \bar{b}_k }} = u_k \frac{{\phi \left( {\bar{b}_k } \right)}}{{\phi \left( {z_k } \right)}}}$ and $\displaystyle{\frac{{\partial z_k }}{{\partial \underline{b}_k }} = \left( {1 - u_k } \right)\frac{{\phi \left( {\underline{b}_k } \right)}}{{\phi \left( {z_k } \right)}}}$. In most cases, as noted parenthetically, $\displaystyle{\frac{{\partial \bar{b}_k }}{{\partial \delta_m }} = \frac{{\partial \underline{b}_k }}{{\partial \delta_m }}}$, so then we can write $\displaystyle{\frac{{\partial z_k }}{{\partial \delta_m }} = \left( {\frac{{\partial z_k }}{{\partial \bar{b}_k }} + \frac{{\partial z_k }}{{\partial \underline{b}_k }}} \right)\frac{{\partial \bar{b}_k }}{{\partial \delta_m }}}$.

After completing the recursion, derivatives with respect to ${\bf T}$ are transformed into ones with respect to ${\bm {\Sigma}}$ as described in Gates (2006, p. 198). The derivatives of the final simulated probability, which is the average of that computed from many sequences $u_1{\hdots}u_d$, are the averages of the derivatives of each.
\end{document} 